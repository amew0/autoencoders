batch_size: 64
criterion:
  loss: MSELoss
decoder:
- layer:
  - 192
  - 96
  - 2
  - 2
  - 2
  - 0
- act: ReLU
- layer:
  - 96
  - 48
  - 2
  - 2
  - 2
  - 0
- act: ReLU
- layer:
  - 48
  - 1
  - 3
  - 2
  - 1
  - 1
- act: Tanh
encoder:
- layer:
  - 1
  - 48
  - 5
  - 2
  - 2
- act: ReLU
- layer:
  - 48
  - 96
  - 5
  - 1
  - 0
- act: ReLU
- layer:
  - 96
  - 192
  - 2
  - 2
  - 2
- act: ReLU
epochs: 100
optimizer:
  Adam:
    learning_rate: 0.001
    weight_decay: 1.0e-05
seed: 123
