2706505
2f.2
loss=7,5
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 19200
/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
LossID: 7
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 12, 12]             156
            Conv2d-2            [-1, 6, 12, 12]             330
       BatchNorm2d-3            [-1, 6, 12, 12]              12
              ReLU-4            [-1, 6, 12, 12]               0
            Conv2d-5             [-1, 18, 8, 8]           2,718
            Conv2d-6             [-1, 18, 8, 8]           2,934
       BatchNorm2d-7             [-1, 18, 8, 8]              36
              ReLU-8             [-1, 18, 8, 8]               0
            Conv2d-9             [-1, 54, 4, 4]          24,354
           Conv2d-10             [-1, 54, 4, 4]          26,298
      BatchNorm2d-11             [-1, 54, 4, 4]             108
             ReLU-12             [-1, 54, 4, 4]               0
           Conv2d-13            [-1, 108, 2, 2]          52,596
           Conv2d-14            [-1, 108, 2, 2]         105,084
      BatchNorm2d-15            [-1, 108, 2, 2]             216
             ReLU-16            [-1, 108, 2, 2]               0
           Conv2d-17            [-1, 216, 1, 1]          93,528
           Conv2d-18            [-1, 216, 1, 1]         420,120
      BatchNorm2d-19            [-1, 216, 1, 1]             432
             ReLU-20            [-1, 216, 1, 1]               0
          Flatten-21                  [-1, 216]               0
================================================================
Total params: 728,922
Trainable params: 728,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 2.78
Estimated Total Size (MB): 2.89
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Unflatten-1             [-1, 24, 3, 3]               0
   ConvTranspose2d-2            [-1, 192, 6, 6]          41,664
              ReLU-3            [-1, 192, 6, 6]               0
   ConvTranspose2d-4            [-1, 192, 6, 6]         331,968
   ConvTranspose2d-5            [-1, 192, 3, 3]           4,800
              ReLU-6            [-1, 192, 6, 6]               0
    ResidualBlockk-7            [-1, 192, 6, 6]               0
       BatchNorm2d-8            [-1, 192, 6, 6]             384
   ConvTranspose2d-9             [-1, 96, 8, 8]         165,984
             ReLU-10             [-1, 96, 8, 8]               0
  ConvTranspose2d-11             [-1, 96, 8, 8]          83,040
  ConvTranspose2d-12             [-1, 96, 6, 6]          18,528
             ReLU-13             [-1, 96, 8, 8]               0
   ResidualBlockk-14             [-1, 96, 8, 8]               0
      BatchNorm2d-15             [-1, 96, 8, 8]             192
  ConvTranspose2d-16           [-1, 48, 12, 12]          18,480
             ReLU-17           [-1, 48, 12, 12]               0
  ConvTranspose2d-18           [-1, 48, 12, 12]          20,784
  ConvTranspose2d-19             [-1, 48, 8, 8]           4,656
             ReLU-20           [-1, 48, 12, 12]               0
   ResidualBlockk-21           [-1, 48, 12, 12]               0
      BatchNorm2d-22           [-1, 48, 12, 12]              96
  ConvTranspose2d-23            [-1, 1, 24, 24]             433
             ReLU-24            [-1, 1, 24, 24]               0
  ConvTranspose2d-25            [-1, 1, 24, 24]              10
  ConvTranspose2d-26            [-1, 1, 12, 12]              49
             ReLU-27            [-1, 1, 24, 24]               0
   ResidualBlockk-28            [-1, 1, 24, 24]               0
      BatchNorm2d-29            [-1, 1, 24, 24]               2
================================================================
Total params: 691,070
Trainable params: 691,070
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.01
Params size (MB): 2.64
Estimated Total Size (MB): 3.64
----------------------------------------------------------------
Ready to TRAIN!!
Task: Training Epoch @ 000 L: 15.109209 M: 0.895521 S: 0.725571 V: 2.778624 M_LR: 0.479331 !==! Task: Validation Epoch @ 000 L: 12.747765 M: 0.743300 S: 0.935347 V: 2.140287 M_LR: 0.338324
Task: Training Epoch @ 002 L: 11.961910 M: 0.318877 S: 0.992786 V: 1.859905 M_LR: 0.436066 !==! Task: Validation Epoch @ 002 L: 12.354486 M: 0.312037 S: 0.995927 V: 1.846552 M_LR: 0.844496
Task: Training Epoch @ 003 L: 11.864022 M: 0.301215 S: 0.995977 V: 1.764376 M_LR: 0.460151 !==! Task: Validation Epoch @ 003 L: 12.202628 M: 0.299592 S: 0.996973 V: 1.769441 M_LR: 0.413953
Task: Training Epoch @ 004 L: 11.846546 M: 0.300519 S: 0.995936 V: 1.745439 M_LR: 0.473679 !==! Task: Validation Epoch @ 004 L: 12.197853 M: 0.298280 S: 0.996785 V: 1.765195 M_LR: 0.537845
Task: Training Epoch @ 005 L: 11.840449 M: 0.299239 S: 0.995730 V: 1.739004 M_LR: 0.482461 !==! Task: Validation Epoch @ 005 L: 12.194111 M: 0.297621 S: 0.996799 V: 1.761176 M_LR: 0.567657
Task: Training Epoch @ 006 L: 11.833338 M: 0.298102 S: 0.995551 V: 1.731403 M_LR: 0.486798 !==! Task: Validation Epoch @ 006 L: 12.177514 M: 0.296281 S: 0.996351 V: 1.744204 M_LR: 0.562257
Task: Training Epoch @ 008 L: 11.815878 M: 0.297858 S: 0.995311 V: 1.712992 M_LR: 0.499322 !==! Task: Validation Epoch @ 008 L: 12.161035 M: 0.296137 S: 0.995997 V: 1.727724 M_LR: 0.515404
Task: Training Epoch @ 009 L: 11.809985 M: 0.297580 S: 0.995129 V: 1.707548 M_LR: 0.507488 !==! Task: Validation Epoch @ 009 L: 12.155135 M: 0.295796 S: 0.995785 V: 1.721832 M_LR: 0.650575
Task: Training Epoch @ 010 L: 11.803162 M: 0.296517 S: 0.994866 V: 1.700487 M_LR: 0.516852 !==! Task: Validation Epoch @ 010 L: 12.144442 M: 0.294890 S: 0.995658 V: 1.710075 M_LR: 0.544348
Task: Training Epoch @ 011 L: 11.799987 M: 0.296044 S: 0.994760 V: 1.697747 M_LR: 0.515436 !==! Task: Validation Epoch @ 011 L: 12.143515 M: 0.294575 S: 0.995610 V: 1.709214 M_LR: 0.583860
Task: Training Epoch @ 012 L: 11.795584 M: 0.295407 S: 0.994617 V: 1.694955 M_LR: 0.521451 !==! Task: Validation Epoch @ 012 L: 12.142441 M: 0.293663 S: 0.995059 V: 1.706311 M_LR: 0.599492
Task: Training Epoch @ 014 L: 11.790671 M: 0.294300 S: 0.994424 V: 1.690914 M_LR: 0.542441 !==! Task: Validation Epoch @ 014 L: 12.133779 M: 0.292977 S: 0.995077 V: 1.698057 M_LR: 0.505726
Task: Training Epoch @ 015 L: 11.787545 M: 0.293914 S: 0.994364 V: 1.688868 M_LR: 0.549921 !==! Task: Validation Epoch @ 015 L: 12.132393 M: 0.292429 S: 0.994985 V: 1.696392 M_LR: 0.523591
Task: Training Epoch @ 016 L: 11.785869 M: 0.293561 S: 0.994272 V: 1.688433 M_LR: 0.562689 !==! Task: Validation Epoch @ 016 L: 12.136748 M: 0.291814 S: 0.994825 V: 1.697755 M_LR: 0.492224
Task: Training Epoch @ 018 L: 11.781360 M: 0.292779 S: 0.994138 V: 1.687258 M_LR: 0.577488 !==! Task: Validation Epoch @ 018 L: 12.129536 M: 0.291254 S: 0.994394 V: 1.690311 M_LR: 0.599047
Task: Training Epoch @ 019 L: 11.779772 M: 0.292349 S: 0.994117 V: 1.686681 M_LR: 0.583582 !==! Task: Validation Epoch @ 019 L: 12.128635 M: 0.290720 S: 0.994223 V: 1.688707 M_LR: 0.721209
Task: Training Epoch @ 020 L: 11.776608 M: 0.291706 S: 0.993958 V: 1.686723 M_LR: 0.589471 !==! Task: Validation Epoch @ 020 L: 12.134351 M: 0.289895 S: 0.993996 V: 1.690396 M_LR: 0.588366
Task: Training Epoch @ 021 L: 11.774192 M: 0.291079 S: 0.993874 V: 1.686981 M_LR: 0.592861 !==! Task: Validation Epoch @ 021 L: 12.138136 M: 0.289417 S: 0.993539 V: 1.692168 M_LR: 0.652167
Task: Training Epoch @ 022 L: 11.771733 M: 0.290773 S: 0.993864 V: 1.688011 M_LR: 0.597831 !==! Task: Validation Epoch @ 022 L: 12.139485 M: 0.288601 S: 0.993418 V: 1.692124 M_LR: 0.698343
Task: Training Epoch @ 023 L: 11.771848 M: 0.290158 S: 0.993763 V: 1.688009 M_LR: 0.603184 !==! Task: Validation Epoch @ 023 L: 12.138954 M: 0.288276 S: 0.993795 V: 1.694750 M_LR: 0.677976
Task: Training Epoch @ 025 L: 11.765860 M: 0.289620 S: 0.993704 V: 1.688825 M_LR: 0.618086 !==! Task: Validation Epoch @ 025 L: 12.166805 M: 0.286691 S: 0.993298 V: 1.700661 M_LR: 0.636578
Task: Training Epoch @ 030 L: 11.754021 M: 0.286865 S: 0.993368 V: 1.693337 M_LR: 0.634207 !==! Task: Validation Epoch @ 030 L: 12.172526 M: 0.285953 S: 0.992804 V: 1.696779 M_LR: 0.648806
Task: Training Epoch @ 031 L: 11.750631 M: 0.285832 S: 0.993267 V: 1.694610 M_LR: 0.644691 !==! Task: Validation Epoch @ 031 L: 12.173468 M: 0.284698 S: 0.993316 V: 1.700634 M_LR: 0.715669
Task: Training Epoch @ 032 L: 11.753238 M: 0.285700 S: 0.993343 V: 1.698159 M_LR: 0.644712 !==! Task: Validation Epoch @ 032 L: 12.164387 M: 0.284426 S: 0.993400 V: 1.695978 M_LR: 0.631819
Task: Training Epoch @ 033 L: 11.744292 M: 0.285603 S: 0.993441 V: 1.699829 M_LR: 0.649890 !==! Task: Validation Epoch @ 033 L: 12.174104 M: 0.283811 S: 0.993724 V: 1.702750 M_LR: 0.626828
Task: Training Epoch @ 035 L: 11.741092 M: 0.285359 S: 0.993357 V: 1.698671 M_LR: 0.657802 !==! Task: Validation Epoch @ 035 L: 12.213582 M: 0.282801 S: 0.993311 V: 1.704893 M_LR: 0.628509
Task: Training Epoch @ 043 L: 11.640817 M: 0.285935 S: 0.994285 V: 1.728169 M_LR: 0.662741 !==! Task: Validation Epoch @ 043 L: 12.352316 M: 0.279490 S: 0.994175 V: 1.732926 M_LR: 0.655517
Task: Training Epoch @ 050 L: 11.519393 M: 0.285915 S: 0.994316 V: 1.772751 M_LR: 0.663585 !==! Task: Validation Epoch @ 050 L: 12.541878 M: 0.273635 S: 0.993983 V: 1.776629 M_LR: 0.688417
Task: Training Epoch @ 051 L: 11.480692 M: 0.285472 S: 0.994362 V: 1.782930 M_LR: 0.661304 !==! Task: Validation Epoch @ 051 L: 12.610469 M: 0.272634 S: 0.993577 V: 1.771518 M_LR: 0.655491
Task: Training Epoch @ 070 L: 10.546452 M: 0.292953 S: 0.992768 V: 2.032178 M_LR: 0.661831 !==! Task: Validation Epoch @ 070 L: 14.183160 M: 0.268787 S: 0.991952 V: 1.977121 M_LR: 0.629475
Tolerance: 3!! Task: Training Epoch @ 091 L: 8.324343 M: 0.304078 S: 0.985594 V: 2.137893 M_LR: 0.670312 !==! Task: Validation Epoch @ 091 L: 15.151620 M: 0.284309 S: 0.992264 V: 2.009088 M_LR: 0.678780
Task: Training Epoch @ 106 L: 7.393931 M: 0.309887 S: 0.982232 V: 2.143145 M_LR: 0.675818 !==! Task: Validation Epoch @ 106 L: 15.328381 M: 0.268264 S: 0.988632 V: 2.030878 M_LR: 0.677336
Task: Training Epoch @ 109 L: 7.096298 M: 0.310088 S: 0.980919 V: 2.134452 M_LR: 0.675574 !==! Task: Validation Epoch @ 109 L: 15.069643 M: 0.267293 S: 0.989424 V: 2.033487 M_LR: 0.685393
Task: Training Epoch @ 121 L: 6.486983 M: 0.307713 S: 0.977224 V: 2.112403 M_LR: 0.678222 !==! Task: Validation Epoch @ 121 L: 15.395189 M: 0.255469 S: 0.988922 V: 2.013579 M_LR: 0.663332
Task: Training Epoch @ 124 L: 6.363687 M: 0.308294 S: 0.976394 V: 2.104787 M_LR: 0.683717 !==! Task: Validation Epoch @ 124 L: 15.112956 M: 0.248078 S: 0.987171 V: 1.981483 M_LR: 0.688761
Task: Training Epoch @ 126 L: 6.107405 M: 0.304354 S: 0.974675 V: 2.090465 M_LR: 0.687009 !==! Task: Validation Epoch @ 126 L: 15.126869 M: 0.237588 S: 0.985465 V: 1.981699 M_LR: 0.692326
Tolerance: 2!! Task: Training Epoch @ 147 L: 5.778998 M: 0.301660 S: 0.969466 V: 2.069344 M_LR: 0.703285 !==! Task: Validation Epoch @ 147 L: 15.429011 M: 0.259729 S: 0.979710 V: 2.020448 M_LR: 0.738896
Task: Training Epoch @ 159 L: 5.290538 M: 0.295935 S: 0.962106 V: 2.027510 M_LR: 0.717599 !==! Task: Validation Epoch @ 159 L: 15.474944 M: 0.235328 S: 0.978481 V: 1.953718 M_LR: 0.743272
Task: Training Epoch @ 173 L: 5.289559 M: 0.292760 S: 0.958846 V: 2.024363 M_LR: 0.721027 !==! Task: Validation Epoch @ 173 L: 15.368184 M: 0.226075 S: 0.970662 V: 1.958719 M_LR: 0.740629
Task: Training Epoch @ 182 L: 4.899943 M: 0.292233 S: 0.952046 V: 1.992007 M_LR: 0.724825 !==! Task: Validation Epoch @ 182 L: 14.933259 M: 0.220650 S: 0.978459 V: 1.922843 M_LR: 0.725732
Task: Training Epoch @ 186 L: 4.764438 M: 0.289600 S: 0.946539 V: 1.976288 M_LR: 0.730342 !==! Task: Validation Epoch @ 186 L: 15.370373 M: 0.216243 S: 0.967621 V: 1.939007 M_LR: 0.757922
Task: Training Epoch @ 188 L: 4.717415 M: 0.287049 S: 0.946830 V: 1.967293 M_LR: 0.733885 !==! Task: Validation Epoch @ 188 L: 15.070385 M: 0.205009 S: 0.974731 V: 1.898411 M_LR: 0.753353
Task: Testing Epoch @ -01 L: 14.364311 M: 0.194116 S: 0.973933 V: 1.881370 M_LR: 0.803835
written to: ./models/v2lr/2f.2.20231227063332_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 6331.810867071152 seconds.
LossID: 5
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 12, 12]             156
            Conv2d-2            [-1, 6, 12, 12]             330
       BatchNorm2d-3            [-1, 6, 12, 12]              12
              ReLU-4            [-1, 6, 12, 12]               0
            Conv2d-5             [-1, 18, 8, 8]           2,718
            Conv2d-6             [-1, 18, 8, 8]           2,934
       BatchNorm2d-7             [-1, 18, 8, 8]              36
              ReLU-8             [-1, 18, 8, 8]               0
            Conv2d-9             [-1, 54, 4, 4]          24,354
           Conv2d-10             [-1, 54, 4, 4]          26,298
      BatchNorm2d-11             [-1, 54, 4, 4]             108
             ReLU-12             [-1, 54, 4, 4]               0
           Conv2d-13            [-1, 108, 2, 2]          52,596
           Conv2d-14            [-1, 108, 2, 2]         105,084
      BatchNorm2d-15            [-1, 108, 2, 2]             216
             ReLU-16            [-1, 108, 2, 2]               0
           Conv2d-17            [-1, 216, 1, 1]          93,528
           Conv2d-18            [-1, 216, 1, 1]         420,120
      BatchNorm2d-19            [-1, 216, 1, 1]             432
             ReLU-20            [-1, 216, 1, 1]               0
          Flatten-21                  [-1, 216]               0
================================================================
Total params: 728,922
Trainable params: 728,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 2.78
Estimated Total Size (MB): 2.89
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Unflatten-1             [-1, 24, 3, 3]               0
   ConvTranspose2d-2            [-1, 192, 6, 6]          41,664
              ReLU-3            [-1, 192, 6, 6]               0
   ConvTranspose2d-4            [-1, 192, 6, 6]         331,968
   ConvTranspose2d-5            [-1, 192, 3, 3]           4,800
              ReLU-6            [-1, 192, 6, 6]               0
    ResidualBlockk-7            [-1, 192, 6, 6]               0
       BatchNorm2d-8            [-1, 192, 6, 6]             384
   ConvTranspose2d-9             [-1, 96, 8, 8]         165,984
             ReLU-10             [-1, 96, 8, 8]               0
  ConvTranspose2d-11             [-1, 96, 8, 8]          83,040
  ConvTranspose2d-12             [-1, 96, 6, 6]          18,528
             ReLU-13             [-1, 96, 8, 8]               0
   ResidualBlockk-14             [-1, 96, 8, 8]               0
      BatchNorm2d-15             [-1, 96, 8, 8]             192
  ConvTranspose2d-16           [-1, 48, 12, 12]          18,480
             ReLU-17           [-1, 48, 12, 12]               0
  ConvTranspose2d-18           [-1, 48, 12, 12]          20,784
  ConvTranspose2d-19             [-1, 48, 8, 8]           4,656
             ReLU-20           [-1, 48, 12, 12]               0
   ResidualBlockk-21           [-1, 48, 12, 12]               0
      BatchNorm2d-22           [-1, 48, 12, 12]              96
  ConvTranspose2d-23            [-1, 1, 24, 24]             433
             ReLU-24            [-1, 1, 24, 24]               0
  ConvTranspose2d-25            [-1, 1, 24, 24]              10
  ConvTranspose2d-26            [-1, 1, 12, 12]              49
             ReLU-27            [-1, 1, 24, 24]               0
   ResidualBlockk-28            [-1, 1, 24, 24]               0
      BatchNorm2d-29            [-1, 1, 24, 24]               2
================================================================
Total params: 691,070
Trainable params: 691,070
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.01
Params size (MB): 2.64
Estimated Total Size (MB): 3.64
----------------------------------------------------------------
Task: Training Epoch @ 000 L: 1.125048 M: 0.965421 S: 0.464213 V: 5.067984 M_LR: 0.754848 !==! Task: Validation Epoch @ 000 L: 1.068188 M: 1.064515 S: 0.636164 V: 4.740655 M_LR: 0.765636
Tolerance: 3!! Task: Training Epoch @ 021 L: 1.009432 M: 0.321970 S: 0.996341 V: 1.800342 M_LR: 0.757190 !==! Task: Validation Epoch @ 021 L: 1.208473 M: 4.370023 S: 0.992007 V: 2.057419 M_LR: 0.786030
Tolerance: 2!! Task: Training Epoch @ 042 L: 1.009432 M: 0.321970 S: 0.996341 V: 1.800342 M_LR: 0.757190 !==! Task: Validation Epoch @ 042 L: 1.208473 M: 4.370023 S: 0.992007 V: 2.057419 M_LR: 0.786030
Tolerance: 1!! Task: Training Epoch @ 063 L: 1.009432 M: 0.321970 S: 0.996341 V: 1.800342 M_LR: 0.757190 !==! Task: Validation Epoch @ 063 L: 1.208473 M: 4.370023 S: 0.992007 V: 2.057419 M_LR: 0.786030
Task: Testing Epoch @ -01 L: 1.025846 M: 1.047184 S: 0.642469 V: 4.705459 M_LR: 0.806194
written to: ./models/v2lr/2f.2.20231227081858_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 1878.1501951217651 seconds.
