2603395
1.2.3
from 1.2 with lots of added 2 hidden layers
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 24000
Iteration config: 0
[Linear(in_features=216, out_features=512, bias=True), ReLU(), Linear(in_features=512, out_features=512, bias=True), ReLU(), Linear(in_features=512, out_features=216, bias=True), ReLU()]


----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1              [-1, 8, 8, 8]              80
       BatchNorm2d-2              [-1, 8, 8, 8]              16
            Conv2d-3              [-1, 8, 8, 8]             584
              ReLU-4              [-1, 8, 8, 8]               0
            Conv2d-5             [-1, 16, 6, 6]           1,168
       BatchNorm2d-6             [-1, 16, 6, 6]              32
            Conv2d-7             [-1, 16, 6, 6]           2,320
              ReLU-8             [-1, 16, 6, 6]               0
            Conv2d-9             [-1, 24, 3, 3]           3,480
      BatchNorm2d-10             [-1, 24, 3, 3]              48
           Conv2d-11             [-1, 24, 3, 3]           5,208
             ReLU-12             [-1, 24, 3, 3]               0
          Flatten-13                  [-1, 216]               0
           Linear-14                  [-1, 512]         111,104
             ReLU-15                  [-1, 512]               0
           Linear-16                  [-1, 512]         262,656
             ReLU-17                  [-1, 512]               0
           Linear-18                  [-1, 216]         110,808
             ReLU-19                  [-1, 216]               0
================================================================
Total params: 497,504
Trainable params: 497,504
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 1.90
Estimated Total Size (MB): 1.96
----------------------------------------------------------------
None
Reconstructor from: ./models/img/14.2.20231110000321.pt
Task: v2lr, Epoch:1, Loss:0.922369                	Task: InvProb, Epoch:1, MSELoss:0.104023, SSIM:0.31384416532644777
Task: v2lr, Epoch:11, Loss:0.761994                	Task: InvProb, Epoch:11, MSELoss:0.079984, SSIM:0.26459143113679184
Task: v2lr, Epoch:21, Loss:0.452875                	Task: InvProb, Epoch:21, MSELoss:0.108842, SSIM:0.3031940781356527
Task: v2lr, Epoch:31, Loss:0.502563                	Task: InvProb, Epoch:31, MSELoss:0.067451, SSIM:0.2593617597773449
Task: v2lr, Epoch:41, Loss:0.702896                	Task: InvProb, Epoch:41, MSELoss:0.058887, SSIM:0.278564901772851
Task: v2lr, Epoch:51, Loss:0.406996                	Task: InvProb, Epoch:51, MSELoss:0.082204, SSIM:0.2800282561249092
Task: v2lr, Epoch:61, Loss:0.300125                	Task: InvProb, Epoch:61, MSELoss:0.080153, SSIM:0.20947726554208923
Task: v2lr, Epoch:71, Loss:0.261521                	Task: InvProb, Epoch:71, MSELoss:0.155510, SSIM:0.21558849038759464
Task: v2lr, Epoch:81, Loss:0.295590                	Task: InvProb, Epoch:81, MSELoss:0.141068, SSIM:0.2239075166824267
Task: v2lr, Epoch:91, Loss:0.379403                	Task: InvProb, Epoch:91, MSELoss:0.102421, SSIM:0.2707607639650851
Task: v2lr, Epoch:101, Loss:0.378882                	Task: InvProb, Epoch:101, MSELoss:0.090426, SSIM:0.24525362328167533
Task: v2lr, Epoch:111, Loss:0.358904                	Task: InvProb, Epoch:111, MSELoss:0.106463, SSIM:0.26097391320978536
Task: v2lr, Epoch:121, Loss:0.525359                	Task: InvProb, Epoch:121, MSELoss:0.070556, SSIM:0.26529978406387655
Task: v2lr, Epoch:131, Loss:0.353266                	Task: InvProb, Epoch:131, MSELoss:0.136303, SSIM:0.24246139239916797
Task: v2lr, Epoch:141, Loss:0.304742                	Task: InvProb, Epoch:141, MSELoss:0.137267, SSIM:0.2311143380945042
Task: v2lr, Epoch:151, Loss:0.300327                	Task: InvProb, Epoch:151, MSELoss:0.123780, SSIM:0.22743258410246348
Task: v2lr, Epoch:161, Loss:0.341086                	Task: InvProb, Epoch:161, MSELoss:0.096475, SSIM:0.23373255161310558
Task: v2lr, Epoch:171, Loss:0.307492                	Task: InvProb, Epoch:171, MSELoss:0.124746, SSIM:0.2286876687935283
Task: v2lr, Epoch:181, Loss:0.337307                	Task: InvProb, Epoch:181, MSELoss:0.187389, SSIM:0.20666456838099734
Task: v2lr, Epoch:191, Loss:0.282301                	Task: InvProb, Epoch:191, MSELoss:0.194285, SSIM:0.21393393307156028
Task: v2lr, Epoch:200, Loss:0.524586                	Task: InvProb, Epoch:200, MSELoss:0.369048, SSIM:0.21578522070317863
Avg Test Loss: 0.6967712272355954
Max Test Loss: 4.831545829772949
Min Test Loss: 0.06918691843748093
written to: ./models/v2lr/1.2.3.20231128023116_v2lr.pth
written to: ./models/v2lr/1.2.3.20231128023116_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 5374.4547736644745 seconds.
Iteration config: 1
[Linear(in_features=216, out_features=512, bias=True), ReLU(), Linear(in_features=512, out_features=432, bias=True), ReLU(), Linear(in_features=432, out_features=216, bias=True), ReLU()]


----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1              [-1, 8, 8, 8]              80
       BatchNorm2d-2              [-1, 8, 8, 8]              16
            Conv2d-3              [-1, 8, 8, 8]             584
              ReLU-4              [-1, 8, 8, 8]               0
            Conv2d-5             [-1, 16, 6, 6]           1,168
       BatchNorm2d-6             [-1, 16, 6, 6]              32
            Conv2d-7             [-1, 16, 6, 6]           2,320
              ReLU-8             [-1, 16, 6, 6]               0
            Conv2d-9             [-1, 24, 3, 3]           3,480
      BatchNorm2d-10             [-1, 24, 3, 3]              48
           Conv2d-11             [-1, 24, 3, 3]           5,208
             ReLU-12             [-1, 24, 3, 3]               0
          Flatten-13                  [-1, 216]               0
           Linear-14                  [-1, 512]         111,104
             ReLU-15                  [-1, 512]               0
           Linear-16                  [-1, 432]         221,616
             ReLU-17                  [-1, 432]               0
           Linear-18                  [-1, 216]          93,528
             ReLU-19                  [-1, 216]               0
================================================================
Total params: 439,184
Trainable params: 439,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 1.68
Estimated Total Size (MB): 1.74
----------------------------------------------------------------
None
Reconstructor from: ./models/img/14.2.20231110000321.pt
Task: v2lr, Epoch:1, Loss:0.957122                	Task: InvProb, Epoch:1, MSELoss:0.104912, SSIM:0.29163652604145396
Task: v2lr, Epoch:11, Loss:0.830639                	Task: InvProb, Epoch:11, MSELoss:0.085270, SSIM:0.29253683929155416
Task: v2lr, Epoch:21, Loss:0.472989                	Task: InvProb, Epoch:21, MSELoss:0.063442, SSIM:0.249490762784623
Task: v2lr, Epoch:31, Loss:0.583545                	Task: InvProb, Epoch:31, MSELoss:0.097975, SSIM:0.24983958024773334
Task: v2lr, Epoch:41, Loss:0.495004                	Task: InvProb, Epoch:41, MSELoss:0.222399, SSIM:0.29648586042428127
Task: v2lr, Epoch:51, Loss:0.486095                	Task: InvProb, Epoch:51, MSELoss:0.106566, SSIM:0.3083433738018597
Task: v2lr, Epoch:61, Loss:0.635628                	Task: InvProb, Epoch:61, MSELoss:0.072891, SSIM:0.2970866296514596
Task: v2lr, Epoch:71, Loss:0.838888                	Task: InvProb, Epoch:71, MSELoss:0.081183, SSIM:0.3486436960759586
Task: v2lr, Epoch:81, Loss:0.383432                	Task: InvProb, Epoch:81, MSELoss:0.055273, SSIM:0.21538215417077922
Task: v2lr, Epoch:91, Loss:0.721393                	Task: InvProb, Epoch:91, MSELoss:0.079979, SSIM:0.33608219428875474
Task: v2lr, Epoch:101, Loss:0.266763                	Task: InvProb, Epoch:101, MSELoss:0.126889, SSIM:0.2394101493135633
Task: v2lr, Epoch:111, Loss:0.361503                	Task: InvProb, Epoch:111, MSELoss:0.123572, SSIM:0.22392957444771888
Task: v2lr, Epoch:121, Loss:0.714507                	Task: InvProb, Epoch:121, MSELoss:0.463790, SSIM:0.22655379233263317
Task: v2lr, Epoch:131, Loss:0.289296                	Task: InvProb, Epoch:131, MSELoss:0.095069, SSIM:0.25272655454726134
Task: v2lr, Epoch:141, Loss:0.339520                	Task: InvProb, Epoch:141, MSELoss:0.338634, SSIM:0.1964669247952936
Task: v2lr, Epoch:151, Loss:0.257682                	Task: InvProb, Epoch:151, MSELoss:0.110229, SSIM:0.24605467330218755
Task: v2lr, Epoch:161, Loss:0.211339                	Task: InvProb, Epoch:161, MSELoss:0.123312, SSIM:0.19779889704453635
Task: v2lr, Epoch:171, Loss:0.250200                	Task: InvProb, Epoch:171, MSELoss:0.200849, SSIM:0.24119606589963893
Task: v2lr, Epoch:181, Loss:0.515500                	Task: InvProb, Epoch:181, MSELoss:0.418810, SSIM:0.22553482557840132
Task: v2lr, Epoch:191, Loss:0.705978                	Task: InvProb, Epoch:191, MSELoss:0.612470, SSIM:0.20998270576050093
Task: v2lr, Epoch:200, Loss:0.235822                	Task: InvProb, Epoch:200, MSELoss:0.090959, SSIM:0.2023233727492827
Avg Test Loss: 0.6949623807022969
Max Test Loss: 4.433600902557373
Min Test Loss: 0.08482879400253296
written to: ./models/v2lr/1.2.3.20231128040048_v2lr.pth
written to: ./models/v2lr/1.2.3.20231128040048_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 10775.408247470856 seconds.
Iteration config: 2
[Linear(in_features=216, out_features=512, bias=True), ReLU(), Linear(in_features=512, out_features=324, bias=True), ReLU(), Linear(in_features=324, out_features=216, bias=True), ReLU()]


----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1              [-1, 8, 8, 8]              80
       BatchNorm2d-2              [-1, 8, 8, 8]              16
            Conv2d-3              [-1, 8, 8, 8]             584
              ReLU-4              [-1, 8, 8, 8]               0
            Conv2d-5             [-1, 16, 6, 6]           1,168
       BatchNorm2d-6             [-1, 16, 6, 6]              32
            Conv2d-7             [-1, 16, 6, 6]           2,320
              ReLU-8             [-1, 16, 6, 6]               0
            Conv2d-9             [-1, 24, 3, 3]           3,480
      BatchNorm2d-10             [-1, 24, 3, 3]              48
           Conv2d-11             [-1, 24, 3, 3]           5,208
             ReLU-12             [-1, 24, 3, 3]               0
          Flatten-13                  [-1, 216]               0
           Linear-14                  [-1, 512]         111,104
             ReLU-15                  [-1, 512]               0
           Linear-16                  [-1, 324]         166,212
             ReLU-17                  [-1, 324]               0
           Linear-18                  [-1, 216]          70,200
             ReLU-19                  [-1, 216]               0
================================================================
Total params: 360,452
Trainable params: 360,452
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 1.38
Estimated Total Size (MB): 1.43
----------------------------------------------------------------
None
Reconstructor from: ./models/img/14.2.20231110000321.pt
Task: v2lr, Epoch:1, Loss:0.900549                	Task: InvProb, Epoch:1, MSELoss:0.103776, SSIM:0.30002433803015205
Task: v2lr, Epoch:11, Loss:0.797125                	Task: InvProb, Epoch:11, MSELoss:0.088701, SSIM:0.2815194848592737
Task: v2lr, Epoch:21, Loss:0.530878                	Task: InvProb, Epoch:21, MSELoss:0.068773, SSIM:0.3153098796730984
Task: v2lr, Epoch:31, Loss:0.686719                	Task: InvProb, Epoch:31, MSELoss:0.070968, SSIM:0.32983150445985554
Task: v2lr, Epoch:41, Loss:0.224440                	Task: InvProb, Epoch:41, MSELoss:0.104617, SSIM:0.1906537310559926
Task: v2lr, Epoch:51, Loss:0.287335                	Task: InvProb, Epoch:51, MSELoss:0.105020, SSIM:0.2578815169995662
Task: v2lr, Epoch:61, Loss:0.306043                	Task: InvProb, Epoch:61, MSELoss:0.088367, SSIM:0.29242953258148763
Task: v2lr, Epoch:71, Loss:0.351215                	Task: InvProb, Epoch:71, MSELoss:0.074876, SSIM:0.25537443901011714
Task: v2lr, Epoch:81, Loss:0.297498                	Task: InvProb, Epoch:81, MSELoss:0.094040, SSIM:0.29176738857814066
Task: v2lr, Epoch:91, Loss:0.387874                	Task: InvProb, Epoch:91, MSELoss:0.147081, SSIM:0.3157382568796425
Task: v2lr, Epoch:101, Loss:0.362087                	Task: InvProb, Epoch:101, MSELoss:0.092337, SSIM:0.24802329975485438
Task: v2lr, Epoch:111, Loss:0.539244                	Task: InvProb, Epoch:111, MSELoss:0.078104, SSIM:0.3075446710806491
Task: v2lr, Epoch:121, Loss:0.356349                	Task: InvProb, Epoch:121, MSELoss:0.125617, SSIM:0.28963106399298477
Task: v2lr, Epoch:131, Loss:0.282904                	Task: InvProb, Epoch:131, MSELoss:0.121108, SSIM:0.26250864096584325
Task: v2lr, Epoch:141, Loss:0.392849                	Task: InvProb, Epoch:141, MSELoss:0.088675, SSIM:0.2947065449701738
Task: v2lr, Epoch:151, Loss:0.292335                	Task: InvProb, Epoch:151, MSELoss:0.148916, SSIM:0.2699526802997534
Task: v2lr, Epoch:161, Loss:0.539316                	Task: InvProb, Epoch:161, MSELoss:0.054380, SSIM:0.3481619325381292
Task: v2lr, Epoch:171, Loss:0.272801                	Task: InvProb, Epoch:171, MSELoss:0.134260, SSIM:0.24745756692914167
Task: v2lr, Epoch:181, Loss:0.211000                	Task: InvProb, Epoch:181, MSELoss:0.090068, SSIM:0.22712651510051385
Task: v2lr, Epoch:191, Loss:0.238413                	Task: InvProb, Epoch:191, MSELoss:0.073495, SSIM:0.26368451270876503
Task: v2lr, Epoch:200, Loss:0.436075                	Task: InvProb, Epoch:200, MSELoss:0.225221, SSIM:0.2931561860359805
Avg Test Loss: 0.6909353254983822
Max Test Loss: 4.440526008605957
Min Test Loss: 0.07099543511867523
written to: ./models/v2lr/1.2.3.20231128053049_v2lr.pth
written to: ./models/v2lr/1.2.3.20231128053049_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 16214.44881772995 seconds.
Iteration config: 3
[Linear(in_features=216, out_features=512, bias=True), ReLU(), Linear(in_features=512, out_features=256, bias=True), ReLU(), Linear(in_features=256, out_features=216, bias=True), ReLU()]


----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1              [-1, 8, 8, 8]              80
       BatchNorm2d-2              [-1, 8, 8, 8]              16
            Conv2d-3              [-1, 8, 8, 8]             584
              ReLU-4              [-1, 8, 8, 8]               0
            Conv2d-5             [-1, 16, 6, 6]           1,168
       BatchNorm2d-6             [-1, 16, 6, 6]              32
            Conv2d-7             [-1, 16, 6, 6]           2,320
              ReLU-8             [-1, 16, 6, 6]               0
            Conv2d-9             [-1, 24, 3, 3]           3,480
      BatchNorm2d-10             [-1, 24, 3, 3]              48
           Conv2d-11             [-1, 24, 3, 3]           5,208
             ReLU-12             [-1, 24, 3, 3]               0
          Flatten-13                  [-1, 216]               0
           Linear-14                  [-1, 512]         111,104
             ReLU-15                  [-1, 512]               0
           Linear-16                  [-1, 256]         131,328
             ReLU-17                  [-1, 256]               0
           Linear-18                  [-1, 216]          55,512
             ReLU-19                  [-1, 216]               0
================================================================
Total params: 310,880
Trainable params: 310,880
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 1.19
Estimated Total Size (MB): 1.24
----------------------------------------------------------------
None
Reconstructor from: ./models/img/14.2.20231110000321.pt
Task: v2lr, Epoch:1, Loss:0.949862                	Task: InvProb, Epoch:1, MSELoss:0.101751, SSIM:0.29881442537126446
Task: v2lr, Epoch:11, Loss:0.769705                	Task: InvProb, Epoch:11, MSELoss:0.083201, SSIM:0.272083408270988
Task: v2lr, Epoch:21, Loss:0.728748                	Task: InvProb, Epoch:21, MSELoss:0.077171, SSIM:0.28366762256000355
Task: v2lr, Epoch:31, Loss:0.618792                	Task: InvProb, Epoch:31, MSELoss:0.073736, SSIM:0.2872433776481723
Task: v2lr, Epoch:41, Loss:0.597279                	Task: InvProb, Epoch:41, MSELoss:0.066013, SSIM:0.29195840836635867
Task: v2lr, Epoch:51, Loss:0.343451                	Task: InvProb, Epoch:51, MSELoss:0.123681, SSIM:0.2653196016495216
Task: v2lr, Epoch:61, Loss:0.454673                	Task: InvProb, Epoch:61, MSELoss:0.123635, SSIM:0.27832160808019357
Task: v2lr, Epoch:71, Loss:0.330134                	Task: InvProb, Epoch:71, MSELoss:0.176697, SSIM:0.24099090965858871
Task: v2lr, Epoch:81, Loss:0.381862                	Task: InvProb, Epoch:81, MSELoss:0.270756, SSIM:0.21571811358417337
Task: v2lr, Epoch:91, Loss:0.680118                	Task: InvProb, Epoch:91, MSELoss:0.093901, SSIM:0.33698465373083175
Task: v2lr, Epoch:101, Loss:0.363681                	Task: InvProb, Epoch:101, MSELoss:0.205996, SSIM:0.2547428465884366
Task: v2lr, Epoch:111, Loss:0.386104                	Task: InvProb, Epoch:111, MSELoss:0.104497, SSIM:0.2751544796725389
Task: v2lr, Epoch:121, Loss:0.643659                	Task: InvProb, Epoch:121, MSELoss:0.074285, SSIM:0.3170990682421523
Task: v2lr, Epoch:131, Loss:0.329806                	Task: InvProb, Epoch:131, MSELoss:0.121223, SSIM:0.26510617817510607
Task: v2lr, Epoch:141, Loss:0.914125                	Task: InvProb, Epoch:141, MSELoss:0.124108, SSIM:0.32894580079783353
Task: v2lr, Epoch:151, Loss:0.369967                	Task: InvProb, Epoch:151, MSELoss:0.110845, SSIM:0.24117786038718725
Task: v2lr, Epoch:161, Loss:0.318737                	Task: InvProb, Epoch:161, MSELoss:0.182898, SSIM:0.26534955590836606
Task: v2lr, Epoch:171, Loss:0.342229                	Task: InvProb, Epoch:171, MSELoss:0.171148, SSIM:0.27719324600429374
Task: v2lr, Epoch:181, Loss:0.445223                	Task: InvProb, Epoch:181, MSELoss:0.183881, SSIM:0.24366835177550616
Task: v2lr, Epoch:191, Loss:0.480558                	Task: InvProb, Epoch:191, MSELoss:0.350438, SSIM:0.21615018583245482
slurmstepd: error: *** JOB 2603395 ON gpu-11-3 CANCELLED AT 2023-11-28T08:31:19 DUE TO TIME LIMIT ***
