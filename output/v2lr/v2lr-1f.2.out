2706508
1f.2
loss=7,5
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 19200
/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
LossID: 7
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 256]               0
            Linear-2                  [-1, 128]          32,896
              ReLU-3                  [-1, 128]               0
            Linear-4                  [-1, 216]          27,864
              ReLU-5                  [-1, 216]               0
================================================================
Total params: 60,760
Trainable params: 60,760
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.23
Estimated Total Size (MB): 0.24
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Unflatten-1             [-1, 24, 3, 3]               0
   ConvTranspose2d-2            [-1, 192, 6, 6]          41,664
              ReLU-3            [-1, 192, 6, 6]               0
   ConvTranspose2d-4            [-1, 192, 6, 6]         331,968
   ConvTranspose2d-5            [-1, 192, 3, 3]           4,800
              ReLU-6            [-1, 192, 6, 6]               0
    ResidualBlockk-7            [-1, 192, 6, 6]               0
       BatchNorm2d-8            [-1, 192, 6, 6]             384
   ConvTranspose2d-9             [-1, 96, 8, 8]         165,984
             ReLU-10             [-1, 96, 8, 8]               0
  ConvTranspose2d-11             [-1, 96, 8, 8]          83,040
  ConvTranspose2d-12             [-1, 96, 6, 6]          18,528
             ReLU-13             [-1, 96, 8, 8]               0
   ResidualBlockk-14             [-1, 96, 8, 8]               0
      BatchNorm2d-15             [-1, 96, 8, 8]             192
  ConvTranspose2d-16           [-1, 48, 12, 12]          18,480
             ReLU-17           [-1, 48, 12, 12]               0
  ConvTranspose2d-18           [-1, 48, 12, 12]          20,784
  ConvTranspose2d-19             [-1, 48, 8, 8]           4,656
             ReLU-20           [-1, 48, 12, 12]               0
   ResidualBlockk-21           [-1, 48, 12, 12]               0
      BatchNorm2d-22           [-1, 48, 12, 12]              96
  ConvTranspose2d-23            [-1, 1, 24, 24]             433
             ReLU-24            [-1, 1, 24, 24]               0
  ConvTranspose2d-25            [-1, 1, 24, 24]              10
  ConvTranspose2d-26            [-1, 1, 12, 12]              49
             ReLU-27            [-1, 1, 24, 24]               0
   ResidualBlockk-28            [-1, 1, 24, 24]               0
      BatchNorm2d-29            [-1, 1, 24, 24]               2
================================================================
Total params: 691,070
Trainable params: 691,070
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.01
Params size (MB): 2.64
Estimated Total Size (MB): 3.64
----------------------------------------------------------------
Ready to TRAIN!!
Task: Training Epoch @ 000 L: 14.318769 M: 0.796620 S: 0.798969 V: 2.828848 M_LR: 0.014067 !==! Task: Validation Epoch @ 000 L: 19.052409 M: 56.316812 S: 0.863075 V: 4.101349 M_LR: 0.014504
Task: Training Epoch @ 001 L: 12.202001 M: 0.437204 S: 0.963759 V: 2.063210 M_LR: 0.035269 !==! Task: Validation Epoch @ 001 L: 12.758161 M: 1.410381 S: 0.947579 V: 2.260399 M_LR: 0.015076
Task: Training Epoch @ 003 L: 11.834311 M: 0.297479 S: 0.995251 V: 1.732404 M_LR: 0.038386 !==! Task: Validation Epoch @ 003 L: 13.123590 M: 0.852180 S: 0.950121 V: 2.144682 M_LR: 0.016995
Task: Training Epoch @ 004 L: 11.822206 M: 0.294766 S: 0.994704 V: 1.717724 M_LR: 0.038788 !==! Task: Validation Epoch @ 004 L: 12.189348 M: 0.293050 S: 0.994739 V: 1.748720 M_LR: 0.024177
Task: Training Epoch @ 005 L: 11.810497 M: 0.293118 S: 0.994446 V: 1.705706 M_LR: 0.041185 !==! Task: Validation Epoch @ 005 L: 12.183849 M: 0.290035 S: 0.994137 V: 1.739888 M_LR: 0.029769
Task: Training Epoch @ 006 L: 11.801442 M: 0.290841 S: 0.993995 V: 1.696962 M_LR: 0.059444 !==! Task: Validation Epoch @ 006 L: 12.179336 M: 0.287243 S: 0.994133 V: 1.733325 M_LR: 0.035931
Task: Training Epoch @ 007 L: 11.790555 M: 0.288366 S: 0.993439 V: 1.688206 M_LR: 0.080166 !==! Task: Validation Epoch @ 007 L: 12.178264 M: 0.284318 S: 0.991846 V: 1.721995 M_LR: 0.049428
Task: Training Epoch @ 008 L: 11.779460 M: 0.285419 S: 0.992949 V: 1.682570 M_LR: 0.106079 !==! Task: Validation Epoch @ 008 L: 12.182881 M: 0.281895 S: 0.990714 V: 1.719288 M_LR: 0.063753
Task: Training Epoch @ 009 L: 11.769117 M: 0.282269 S: 0.992525 V: 1.679174 M_LR: 0.135518 !==! Task: Validation Epoch @ 009 L: 12.182662 M: 0.278435 S: 0.990711 V: 1.710554 M_LR: 0.073248
Task: Training Epoch @ 012 L: 11.712785 M: 0.275194 S: 0.992603 V: 1.681858 M_LR: 0.258038 !==! Task: Validation Epoch @ 012 L: 12.219496 M: 0.276616 S: 0.989967 V: 1.708244 M_LR: 0.106780
Task: Training Epoch @ 013 L: 11.685346 M: 0.272147 S: 0.992437 V: 1.690516 M_LR: 0.300719 !==! Task: Validation Epoch @ 013 L: 12.242488 M: 0.274365 S: 0.990503 V: 1.715646 M_LR: 0.111999
Task: Training Epoch @ 015 L: 11.633689 M: 0.267931 S: 0.992678 V: 1.710078 M_LR: 0.382728 !==! Task: Validation Epoch @ 015 L: 12.296511 M: 0.272916 S: 0.990313 V: 1.738767 M_LR: 0.140536
Tolerance: 3!! Task: Training Epoch @ 036 L: 9.880187 M: 0.272819 S: 0.988625 V: 1.939429 M_LR: 1.417332 !==! Task: Validation Epoch @ 036 L: 75.458184 M: 2.157529 S: 0.967518 V: 2.095780 M_LR: 0.243586
Tolerance: 2!! Task: Training Epoch @ 057 L: 7.479712 M: 0.296255 S: 0.966658 V: 1.962914 M_LR: 2.813765 !==! Task: Validation Epoch @ 057 L: 23.060662 M: 1.014756 S: 0.946375 V: 2.108006 M_LR: 0.435017
Tolerance: 1!! Task: Training Epoch @ 078 L: 5.860025 M: 0.293290 S: 0.918669 V: 1.898331 M_LR: 4.745814 !==! Task: Validation Epoch @ 078 L: 17.562941 M: 0.497029 S: 0.944462 V: 1.932067 M_LR: 0.736753
Task: Testing Epoch @ -01 L: 11.877185 M: 0.267547 S: 0.990209 V: 1.732245 M_LR: 0.146098
written to: ./models/v2lr/1f.2.20231227063354_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 2130.313751220703 seconds.
LossID: 5
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 256]               0
            Linear-2                  [-1, 128]          32,896
              ReLU-3                  [-1, 128]               0
            Linear-4                  [-1, 216]          27,864
              ReLU-5                  [-1, 216]               0
================================================================
Total params: 60,760
Trainable params: 60,760
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.23
Estimated Total Size (MB): 0.24
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Unflatten-1             [-1, 24, 3, 3]               0
   ConvTranspose2d-2            [-1, 192, 6, 6]          41,664
              ReLU-3            [-1, 192, 6, 6]               0
   ConvTranspose2d-4            [-1, 192, 6, 6]         331,968
   ConvTranspose2d-5            [-1, 192, 3, 3]           4,800
              ReLU-6            [-1, 192, 6, 6]               0
    ResidualBlockk-7            [-1, 192, 6, 6]               0
       BatchNorm2d-8            [-1, 192, 6, 6]             384
   ConvTranspose2d-9             [-1, 96, 8, 8]         165,984
             ReLU-10             [-1, 96, 8, 8]               0
  ConvTranspose2d-11             [-1, 96, 8, 8]          83,040
  ConvTranspose2d-12             [-1, 96, 6, 6]          18,528
             ReLU-13             [-1, 96, 8, 8]               0
   ResidualBlockk-14             [-1, 96, 8, 8]               0
      BatchNorm2d-15             [-1, 96, 8, 8]             192
  ConvTranspose2d-16           [-1, 48, 12, 12]          18,480
             ReLU-17           [-1, 48, 12, 12]               0
  ConvTranspose2d-18           [-1, 48, 12, 12]          20,784
  ConvTranspose2d-19             [-1, 48, 8, 8]           4,656
             ReLU-20           [-1, 48, 12, 12]               0
   ResidualBlockk-21           [-1, 48, 12, 12]               0
      BatchNorm2d-22           [-1, 48, 12, 12]              96
  ConvTranspose2d-23            [-1, 1, 24, 24]             433
             ReLU-24            [-1, 1, 24, 24]               0
  ConvTranspose2d-25            [-1, 1, 24, 24]              10
  ConvTranspose2d-26            [-1, 1, 12, 12]              49
             ReLU-27            [-1, 1, 24, 24]               0
   ResidualBlockk-28            [-1, 1, 24, 24]               0
      BatchNorm2d-29            [-1, 1, 24, 24]               2
================================================================
Total params: 691,070
Trainable params: 691,070
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.01
Params size (MB): 2.64
Estimated Total Size (MB): 3.64
----------------------------------------------------------------
Task: Training Epoch @ 000 L: 1.078982 M: 0.973072 S: 0.455648 V: 5.817888 M_LR: 4.856715 !==! Task: Validation Epoch @ 000 L: 1.102883 M: 0.823367 S: 0.666680 V: 5.025266 M_LR: 0.757618
Task: Training Epoch @ 002 L: 0.989138 M: 0.611085 S: 0.733109 V: 4.215188 M_LR: 5.042161 !==! Task: Validation Epoch @ 002 L: 1.132489 M: 0.562654 S: 0.800954 V: 4.209899 M_LR: 0.698040
Task: Training Epoch @ 003 L: 0.959767 M: 0.385978 S: 0.950756 V: 3.016424 M_LR: 5.098993 !==! Task: Validation Epoch @ 003 L: 1.154824 M: 0.359229 S: 0.976701 V: 2.729165 M_LR: 0.630493
Tolerance: 3!! Task: Training Epoch @ 024 L: 0.480339 M: 0.853736 S: 0.919882 V: 3.573470 M_LR: 4.110760 !==! Task: Validation Epoch @ 024 L: 1.548454 M: 0.935480 S: 0.951414 V: 3.370372 M_LR: 0.542761
Tolerance: 2!! Task: Training Epoch @ 045 L: 0.214574 M: 1.243086 S: 0.817768 V: 4.127560 M_LR: 4.982809 !==! Task: Validation Epoch @ 045 L: 1.506933 M: 1.208991 S: 0.893525 V: 4.088059 M_LR: 0.727789
Tolerance: 1!! Task: Training Epoch @ 066 L: 0.110450 M: 1.398927 S: 0.830715 V: 4.318454 M_LR: 6.901811 !==! Task: Validation Epoch @ 066 L: 1.405057 M: 1.150034 S: 0.919176 V: 4.125815 M_LR: 0.937298
Task: Testing Epoch @ -01 L: 1.125816 M: 0.351353 S: 0.976700 V: 2.721543 M_LR: 0.707175
written to: ./models/v2lr/1f.2.20231227070919_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 1653.9062130451202 seconds.
