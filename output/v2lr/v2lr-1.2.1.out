2592237
1.2.1
for default data (best so far in 2 conductivity vals)
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 24000
Iteration config: 0
[Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(), Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(), Conv2d(16, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(), Flatten(start_dim=1, end_dim=-1)]


----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1              [-1, 8, 8, 8]              80
       BatchNorm2d-2              [-1, 8, 8, 8]              16
            Conv2d-3              [-1, 8, 8, 8]             584
              ReLU-4              [-1, 8, 8, 8]               0
            Conv2d-5             [-1, 16, 6, 6]           1,168
       BatchNorm2d-6             [-1, 16, 6, 6]              32
            Conv2d-7             [-1, 16, 6, 6]           2,320
              ReLU-8             [-1, 16, 6, 6]               0
            Conv2d-9             [-1, 24, 3, 3]           3,480
      BatchNorm2d-10             [-1, 24, 3, 3]              48
           Conv2d-11             [-1, 24, 3, 3]           5,208
             ReLU-12             [-1, 24, 3, 3]               0
          Flatten-13                  [-1, 216]               0
================================================================
Total params: 12,936
Trainable params: 12,936
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.04
Params size (MB): 0.05
Estimated Total Size (MB): 0.09
----------------------------------------------------------------
None
Reconstructor from: ./models/img/14.2.20231110000321.pt
Task: v2lr, Epoch:1, Loss:0.799357                		Task: InvProb, Epoch:1, MSELoss:0.087577, SSIM:0.3112936666871403
Task: v2lr, Epoch:11, Loss:0.758407                		Task: InvProb, Epoch:11, MSELoss:0.081029, SSIM:0.3035264919598083
Task: v2lr, Epoch:21, Loss:0.708511                		Task: InvProb, Epoch:21, MSELoss:0.080172, SSIM:0.298809392079713
Task: v2lr, Epoch:31, Loss:0.670044                		Task: InvProb, Epoch:31, MSELoss:0.083873, SSIM:0.3061012865549826
Task: v2lr, Epoch:41, Loss:0.683271                		Task: InvProb, Epoch:41, MSELoss:0.085855, SSIM:0.31014676765013316
Task: v2lr, Epoch:51, Loss:0.641216                		Task: InvProb, Epoch:51, MSELoss:0.084069, SSIM:0.3078806817833658
Task: v2lr, Epoch:61, Loss:0.601023                		Task: InvProb, Epoch:61, MSELoss:0.080852, SSIM:0.30848320395702755
Task: v2lr, Epoch:71, Loss:0.612231                		Task: InvProb, Epoch:71, MSELoss:0.080768, SSIM:0.3023991874739701
Task: v2lr, Epoch:81, Loss:0.656753                		Task: InvProb, Epoch:81, MSELoss:0.082957, SSIM:0.3073901918232427
Task: v2lr, Epoch:91, Loss:0.622491                		Task: InvProb, Epoch:91, MSELoss:0.089029, SSIM:0.30831456406544444
Task: v2lr, Epoch:101, Loss:0.592798                		Task: InvProb, Epoch:101, MSELoss:0.084965, SSIM:0.30241478215283535
Task: v2lr, Epoch:111, Loss:0.539085                		Task: InvProb, Epoch:111, MSELoss:0.082239, SSIM:0.2849090364378911
Task: v2lr, Epoch:121, Loss:0.551841                		Task: InvProb, Epoch:121, MSELoss:0.082510, SSIM:0.2861105663983564
Task: v2lr, Epoch:131, Loss:0.558610                		Task: InvProb, Epoch:131, MSELoss:0.079622, SSIM:0.2727807584848081
Task: v2lr, Epoch:141, Loss:0.527534                		Task: InvProb, Epoch:141, MSELoss:0.078413, SSIM:0.2751703400876263
Task: v2lr, Epoch:151, Loss:0.531509                		Task: InvProb, Epoch:151, MSELoss:0.074902, SSIM:0.2701139651947392
Task: v2lr, Epoch:161, Loss:0.464445                		Task: InvProb, Epoch:161, MSELoss:0.074853, SSIM:0.26178914361160366
Task: v2lr, Epoch:171, Loss:0.501692                		Task: InvProb, Epoch:171, MSELoss:0.073954, SSIM:0.26828260847255736
Task: v2lr, Epoch:181, Loss:0.514948                		Task: InvProb, Epoch:181, MSELoss:0.065883, SSIM:0.2649698279835644
Task: v2lr, Epoch:191, Loss:0.537802                		Task: InvProb, Epoch:191, MSELoss:0.065661, SSIM:0.2675380654207191
Task: v2lr, Epoch:200, Loss:0.527098                		Task: InvProb, Epoch:200, MSELoss:0.071709, SSIM:0.255775523822931
Avg Test Loss: 0.6819937833597263
Max Test Loss: 7.154431343078613
Min Test Loss: 0.0966353714466095
written to: ./models/v2lr/1.2.1.20231124075701_v2lr.pth
written to: ./models/v2lr/1.2.1.20231124075701_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 4733.156766176224 seconds.
