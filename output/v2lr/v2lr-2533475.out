0
4 cond linear layer
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 13760
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 256]               0
            Linear-2                  [-1, 216]          55,512
================================================================
Total params: 55,512
Trainable params: 55,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.21
Estimated Total Size (MB): 0.22
----------------------------------------------------------------
None
Task: v2lr, Epoch:1, Loss:0.005762              		Task: InvProb, Epoch:1, Loss:0.001940
Task: v2lr, Epoch:11, Loss:0.005645              		Task: InvProb, Epoch:11, Loss:0.001958
Task: v2lr, Epoch:21, Loss:0.005644              		Task: InvProb, Epoch:21, Loss:0.001958
Task: v2lr, Epoch:31, Loss:0.005644              		Task: InvProb, Epoch:31, Loss:0.001958
Task: v2lr, Epoch:41, Loss:0.005645              		Task: InvProb, Epoch:41, Loss:0.001959
Task: v2lr, Epoch:51, Loss:0.005646              		Task: InvProb, Epoch:51, Loss:0.001959
Task: v2lr, Epoch:61, Loss:0.005646              		Task: InvProb, Epoch:61, Loss:0.001959
Task: v2lr, Epoch:71, Loss:0.005646              		Task: InvProb, Epoch:71, Loss:0.001959
Task: v2lr, Epoch:81, Loss:0.005646              		Task: InvProb, Epoch:81, Loss:0.001959
Task: v2lr, Epoch:91, Loss:0.005646              		Task: InvProb, Epoch:91, Loss:0.001959
Task: v2lr, Epoch:101, Loss:0.005646              		Task: InvProb, Epoch:101, Loss:0.001959
Task: v2lr, Epoch:111, Loss:0.005646              		Task: InvProb, Epoch:111, Loss:0.001959
Task: v2lr, Epoch:121, Loss:0.005646              		Task: InvProb, Epoch:121, Loss:0.001959
Task: v2lr, Epoch:131, Loss:0.005646              		Task: InvProb, Epoch:131, Loss:0.001959
Task: v2lr, Epoch:141, Loss:0.005646              		Task: InvProb, Epoch:141, Loss:0.001959
Task: v2lr, Epoch:151, Loss:0.005646              		Task: InvProb, Epoch:151, Loss:0.001959
Task: v2lr, Epoch:161, Loss:0.005646              		Task: InvProb, Epoch:161, Loss:0.001959
Task: v2lr, Epoch:171, Loss:0.005646              		Task: InvProb, Epoch:171, Loss:0.001959
Task: v2lr, Epoch:181, Loss:0.005646              		Task: InvProb, Epoch:181, Loss:0.001959
Task: v2lr, Epoch:191, Loss:0.005646              		Task: InvProb, Epoch:191, Loss:0.001959
Task: v2lr, Epoch:200, Loss:0.005646              		Task: InvProb, Epoch:200, Loss:0.001959
Avg Test Loss: 0.006873937176410542
Max Test Loss: 0.014846203848719597
Min Test Loss: 0.0017363936640322208
written to: ./results/loss_tracker_v2lr.csv
written to: ./models/v2lr/4_0.20231117012355_v2lr.pth
written to: ./models/v2lr/4_0.20231117012355_v2lr.pt
Elapsed time: 400.5433294773102 seconds.
