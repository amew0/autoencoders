2650696
1.4.2d
1-(pcc+ssim)/2
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 19200
Reconstructor from: ./models/img/14.2.1.retraining.2.20231130014311_img.pt
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 12, 12]             156
              ReLU-2            [-1, 6, 12, 12]               0
            Conv2d-3            [-1, 6, 12, 12]             330
            Conv2d-4            [-1, 6, 16, 16]              12
              ReLU-5            [-1, 6, 12, 12]               0
     ResidualBlock-6            [-1, 6, 12, 12]               0
       BatchNorm2d-7            [-1, 6, 12, 12]              12
            Conv2d-8             [-1, 18, 8, 8]           2,718
              ReLU-9             [-1, 18, 8, 8]               0
           Conv2d-10             [-1, 18, 8, 8]           2,934
           Conv2d-11           [-1, 18, 12, 12]             126
             ReLU-12             [-1, 18, 8, 8]               0
    ResidualBlock-13             [-1, 18, 8, 8]               0
      BatchNorm2d-14             [-1, 18, 8, 8]              36
           Conv2d-15             [-1, 54, 4, 4]          24,354
             ReLU-16             [-1, 54, 4, 4]               0
           Conv2d-17             [-1, 54, 4, 4]          26,298
           Conv2d-18             [-1, 54, 8, 8]           1,026
             ReLU-19             [-1, 54, 4, 4]               0
    ResidualBlock-20             [-1, 54, 4, 4]               0
      BatchNorm2d-21             [-1, 54, 4, 4]             108
           Conv2d-22            [-1, 108, 2, 2]          52,596
             ReLU-23            [-1, 108, 2, 2]               0
           Conv2d-24            [-1, 108, 2, 2]         105,084
           Conv2d-25            [-1, 108, 4, 4]           5,940
             ReLU-26            [-1, 108, 2, 2]               0
    ResidualBlock-27            [-1, 108, 2, 2]               0
      BatchNorm2d-28            [-1, 108, 2, 2]             216
           Conv2d-29            [-1, 216, 1, 1]          93,528
             ReLU-30            [-1, 216, 1, 1]               0
           Conv2d-31            [-1, 216, 1, 1]         420,120
           Conv2d-32            [-1, 216, 2, 2]          23,544
             ReLU-33            [-1, 216, 1, 1]               0
    ResidualBlock-34            [-1, 216, 1, 1]               0
      BatchNorm2d-35            [-1, 216, 1, 1]             432
          Flatten-36                  [-1, 216]               0
================================================================
Total params: 759,570
Trainable params: 759,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.24
Params size (MB): 2.90
Estimated Total Size (MB): 3.14
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Unflatten-1             [-1, 24, 3, 3]               0
   ConvTranspose2d-2            [-1, 192, 6, 6]          41,664
   ConvTranspose2d-3             [-1, 96, 8, 8]         165,984
              ReLU-4             [-1, 96, 8, 8]               0
   ConvTranspose2d-5           [-1, 48, 12, 12]          18,480
              ReLU-6           [-1, 48, 12, 12]               0
   ConvTranspose2d-7            [-1, 1, 24, 24]             433
================================================================
Total params: 226,561
Trainable params: 0
Non-trainable params: 226,561
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.26
Params size (MB): 0.86
Estimated Total Size (MB): 1.12
----------------------------------------------------------------
Ready to TRAIN!!
Task: Training Epoch @ 000 L: 0.717078 M: 0.066180 S: 0.453721  -- V2LR: Epoch M: 0.351913 !==! Task: Validation Epoch @ 000 L: 0.712344 M: 794.659029 S: 0.452395  -- V2LR: Epoch M: 458202.384394
Task: Training Epoch @ 002 L: 0.690180 M: 0.066073 S: 0.424878  -- V2LR: Epoch M: 0.123990 !==! Task: Validation Epoch @ 002 L: 0.699144 M: 21.214266 S: 0.437734  -- V2LR: Epoch M: 47604.798059
Task: Training Epoch @ 003 L: 0.686647 M: 0.066093 S: 0.422282  -- V2LR: Epoch M: 0.105918 !==! Task: Validation Epoch @ 003 L: 0.701554 M: 0.086338 S: 0.432625  -- V2LR: Epoch M: 39.917811
Task: Training Epoch @ 004 L: 0.683603 M: 0.066084 S: 0.421116  -- V2LR: Epoch M: 0.098459 !==! Task: Validation Epoch @ 004 L: 0.684508 M: 0.068304 S: 0.427995  -- V2LR: Epoch M: 0.129558
Task: Training Epoch @ 005 L: 0.682908 M: 0.066087 S: 0.420296  -- V2LR: Epoch M: 0.093748 !==! Task: Validation Epoch @ 005 L: 0.686842 M: 0.068288 S: 0.427681  -- V2LR: Epoch M: 0.093133
Task: Training Epoch @ 006 L: 0.681784 M: 0.066074 S: 0.420541  -- V2LR: Epoch M: 0.090955 !==! Task: Validation Epoch @ 006 L: 0.682716 M: 0.068267 S: 0.428928  -- V2LR: Epoch M: 0.090243
Task: Training Epoch @ 007 L: 0.680411 M: 0.066058 S: 0.421226  -- V2LR: Epoch M: 0.088610 !==! Task: Validation Epoch @ 007 L: 0.685356 M: 0.068264 S: 0.432517  -- V2LR: Epoch M: 0.090346
Task: Training Epoch @ 010 L: 0.677438 M: 0.066038 S: 0.422340  -- V2LR: Epoch M: 0.081219 !==! Task: Validation Epoch @ 010 L: 0.679553 M: 0.068248 S: 0.430679  -- V2LR: Epoch M: 0.081553
Task: Training Epoch @ 011 L: 0.675302 M: 0.066017 S: 0.422517  -- V2LR: Epoch M: 0.079676 !==! Task: Validation Epoch @ 011 L: 0.674120 M: 0.068197 S: 0.429748  -- V2LR: Epoch M: 0.079807
Task: Training Epoch @ 012 L: 0.673767 M: 0.066002 S: 0.422748  -- V2LR: Epoch M: 0.078096 !==! Task: Validation Epoch @ 012 L: 0.672993 M: 0.068187 S: 0.429820  -- V2LR: Epoch M: 0.078025
Task: Training Epoch @ 013 L: 0.672644 M: 0.065987 S: 0.423718  -- V2LR: Epoch M: 0.075884 !==! Task: Validation Epoch @ 013 L: 0.667729 M: 0.068143 S: 0.430786  -- V2LR: Epoch M: 0.074136
Task: Training Epoch @ 014 L: 0.670252 M: 0.065961 S: 0.424048  -- V2LR: Epoch M: 0.070928 !==! Task: Validation Epoch @ 014 L: 0.666949 M: 0.068129 S: 0.431039  -- V2LR: Epoch M: 0.068674
Task: Training Epoch @ 015 L: 0.667315 M: 0.065933 S: 0.424380  -- V2LR: Epoch M: 0.067564 !==! Task: Validation Epoch @ 015 L: 0.666464 M: 0.068108 S: 0.432271  -- V2LR: Epoch M: 0.067534
Task: Training Epoch @ 016 L: 0.664615 M: 0.065908 S: 0.424268  -- V2LR: Epoch M: 0.066396 !==! Task: Validation Epoch @ 016 L: 0.662911 M: 0.068092 S: 0.431006  -- V2LR: Epoch M: 0.066404
Task: Training Epoch @ 017 L: 0.663081 M: 0.065899 S: 0.424011  -- V2LR: Epoch M: 0.066513 !==! Task: Validation Epoch @ 017 L: 0.661836 M: 0.068064 S: 0.431274  -- V2LR: Epoch M: 0.067921
Task: Training Epoch @ 019 L: 0.661629 M: 0.065874 S: 0.424122  -- V2LR: Epoch M: 0.067010 !==! Task: Validation Epoch @ 019 L: 0.658544 M: 0.068002 S: 0.431150  -- V2LR: Epoch M: 0.069441
Task: Training Epoch @ 021 L: 0.657803 M: 0.065839 S: 0.423786  -- V2LR: Epoch M: 0.067592 !==! Task: Validation Epoch @ 021 L: 0.654437 M: 0.067968 S: 0.430925  -- V2LR: Epoch M: 0.069227
Task: Training Epoch @ 023 L: 0.654754 M: 0.065809 S: 0.423565  -- V2LR: Epoch M: 0.070485 !==! Task: Validation Epoch @ 023 L: 0.652834 M: 0.067956 S: 0.430373  -- V2LR: Epoch M: 0.072674
Task: Training Epoch @ 024 L: 0.654366 M: 0.065799 S: 0.423503  -- V2LR: Epoch M: 0.072309 !==! Task: Validation Epoch @ 024 L: 0.652560 M: 0.067915 S: 0.430141  -- V2LR: Epoch M: 0.079867
Task: Training Epoch @ 025 L: 0.652500 M: 0.065776 S: 0.423524  -- V2LR: Epoch M: 0.074139 !==! Task: Validation Epoch @ 025 L: 0.648520 M: 0.067900 S: 0.430092  -- V2LR: Epoch M: 0.074743
Task: Training Epoch @ 026 L: 0.650378 M: 0.065747 S: 0.423670  -- V2LR: Epoch M: 0.075830 !==! Task: Validation Epoch @ 026 L: 0.646487 M: 0.067850 S: 0.430377  -- V2LR: Epoch M: 0.077472
Task: Training Epoch @ 029 L: 0.647219 M: 0.065718 S: 0.423302  -- V2LR: Epoch M: 0.079935 !==! Task: Validation Epoch @ 029 L: 0.640576 M: 0.067770 S: 0.429317  -- V2LR: Epoch M: 0.082553
Task: Training Epoch @ 030 L: 0.646182 M: 0.065689 S: 0.423586  -- V2LR: Epoch M: 0.080652 !==! Task: Validation Epoch @ 030 L: 0.641732 M: 0.067740 S: 0.429649  -- V2LR: Epoch M: 0.082060
Task: Training Epoch @ 033 L: 0.641774 M: 0.065655 S: 0.423412  -- V2LR: Epoch M: 0.083058 !==! Task: Validation Epoch @ 033 L: 0.638910 M: 0.067712 S: 0.429098  -- V2LR: Epoch M: 0.084727
Task: Training Epoch @ 035 L: 0.639522 M: 0.065633 S: 0.423586  -- V2LR: Epoch M: 0.084758 !==! Task: Validation Epoch @ 035 L: 0.637573 M: 0.067682 S: 0.429486  -- V2LR: Epoch M: 0.086908
Task: Training Epoch @ 040 L: 0.636027 M: 0.065612 S: 0.423312  -- V2LR: Epoch M: 0.091574 !==! Task: Validation Epoch @ 040 L: 0.632490 M: 0.067652 S: 0.429890  -- V2LR: Epoch M: 0.094120
Task: Training Epoch @ 048 L: 0.633668 M: 0.065572 S: 0.423475  -- V2LR: Epoch M: 0.101580 !==! Task: Validation Epoch @ 048 L: 0.631233 M: 0.067615 S: 0.429330  -- V2LR: Epoch M: 0.101243
Task: Training Epoch @ 052 L: 0.630890 M: 0.065542 S: 0.423106  -- V2LR: Epoch M: 0.106683 !==! Task: Validation Epoch @ 052 L: 0.631847 M: 0.067603 S: 0.429473  -- V2LR: Epoch M: 0.102489
Task: Training Epoch @ 055 L: 0.631399 M: 0.065539 S: 0.423188  -- V2LR: Epoch M: 0.110035 !==! Task: Validation Epoch @ 055 L: 0.630771 M: 0.067594 S: 0.428942  -- V2LR: Epoch M: 0.109303
Task: Training Epoch @ 057 L: 0.631272 M: 0.065540 S: 0.423231  -- V2LR: Epoch M: 0.112005 !==! Task: Validation Epoch @ 057 L: 0.631502 M: 0.067577 S: 0.428965  -- V2LR: Epoch M: 0.110368
Task: Training Epoch @ 058 L: 0.629878 M: 0.065515 S: 0.423181  -- V2LR: Epoch M: 0.112376 !==! Task: Validation Epoch @ 058 L: 0.630167 M: 0.067563 S: 0.429590  -- V2LR: Epoch M: 0.113880
Task: Training Epoch @ 061 L: 0.629483 M: 0.065520 S: 0.423159  -- V2LR: Epoch M: 0.115517 !==! Task: Validation Epoch @ 061 L: 0.630589 M: 0.067536 S: 0.429113  -- V2LR: Epoch M: 0.114822
Task: Training Epoch @ 063 L: 0.629355 M: 0.065516 S: 0.423107  -- V2LR: Epoch M: 0.116689 !==! Task: Validation Epoch @ 063 L: 0.630079 M: 0.067489 S: 0.429251  -- V2LR: Epoch M: 0.115283
Tolerance: 3!! Task: Training Epoch @ 084 L: 0.627414 M: 0.065478 S: 0.423736  -- V2LR: Epoch M: 0.120174 !==! Task: Validation Epoch @ 084 L: 0.628177 M: 0.067595 S: 0.430147  -- V2LR: Epoch M: 0.114984
Task: Training Epoch @ 098 L: 0.624887 M: 0.065458 S: 0.423701  -- V2LR: Epoch M: 0.125534 !==! Task: Validation Epoch @ 098 L: 0.626898 M: 0.067473 S: 0.429611  -- V2LR: Epoch M: 0.124539
Task: Training Epoch @ 110 L: 0.622607 M: 0.065437 S: 0.423508  -- V2LR: Epoch M: 0.128505 !==! Task: Validation Epoch @ 110 L: 0.625945 M: 0.067473 S: 0.429583  -- V2LR: Epoch M: 0.125759
Task: Training Epoch @ 124 L: 0.621674 M: 0.065425 S: 0.423485  -- V2LR: Epoch M: 0.131484 !==! Task: Validation Epoch @ 124 L: 0.625165 M: 0.067470 S: 0.429836  -- V2LR: Epoch M: 0.130994
Task: Training Epoch @ 127 L: 0.622091 M: 0.065424 S: 0.423988  -- V2LR: Epoch M: 0.131558 !==! Task: Validation Epoch @ 127 L: 0.624866 M: 0.067469 S: 0.429771  -- V2LR: Epoch M: 0.127551
Task: Training Epoch @ 129 L: 0.621668 M: 0.065420 S: 0.423861  -- V2LR: Epoch M: 0.130512 !==! Task: Validation Epoch @ 129 L: 0.626406 M: 0.067456 S: 0.430622  -- V2LR: Epoch M: 0.131220
Task: Training Epoch @ 141 L: 0.619478 M: 0.065419 S: 0.423706  -- V2LR: Epoch M: 0.128116 !==! Task: Validation Epoch @ 141 L: 0.622616 M: 0.067450 S: 0.429283  -- V2LR: Epoch M: 0.128430
Tolerance: 2!! Task: Training Epoch @ 162 L: 0.618469 M: 0.065405 S: 0.423952  -- V2LR: Epoch M: 0.130669 !==! Task: Validation Epoch @ 162 L: 0.624032 M: 0.067485 S: 0.429838  -- V2LR: Epoch M: 0.129599
Task: Training Epoch @ 169 L: 0.617369 M: 0.065393 S: 0.423992  -- V2LR: Epoch M: 0.131944 !==! Task: Validation Epoch @ 169 L: 0.624410 M: 0.067447 S: 0.429863  -- V2LR: Epoch M: 0.128969
Task: Training Epoch @ 170 L: 0.617274 M: 0.065388 S: 0.423824  -- V2LR: Epoch M: 0.131821 !==! Task: Validation Epoch @ 170 L: 0.624326 M: 0.067430 S: 0.430287  -- V2LR: Epoch M: 0.126770
Task: Training Epoch @ 172 L: 0.618803 M: 0.065392 S: 0.424030  -- V2LR: Epoch M: 0.130638 !==! Task: Validation Epoch @ 172 L: 0.626153 M: 0.067423 S: 0.430921  -- V2LR: Epoch M: 0.126845
Task: Training Epoch @ 181 L: 0.616926 M: 0.065385 S: 0.424138  -- V2LR: Epoch M: 0.127684 !==! Task: Validation Epoch @ 181 L: 0.623029 M: 0.067415 S: 0.429962  -- V2LR: Epoch M: 0.126541
Task: Testing Epoch @ -01 L: 0.618428 M: 0.065285 S: 0.427718  -- V2LR: Epoch M: 0.125383
written to: ./models/v2lr/1.4.2d.20231212172033_v2lr.pt
written to: ./results/loss_tracker_v2lr.csv
Elapsed time: 11446.337059020996 seconds.
