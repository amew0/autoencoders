14.2.1.retraining.1
14.2.1.retraining retraining the retraining
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 24000
Only gonna be shown once!
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 48, 12, 12]             480
              ReLU-2           [-1, 48, 12, 12]               0
            Conv2d-3             [-1, 96, 8, 8]          18,528
              ReLU-4             [-1, 96, 8, 8]               0
            Conv2d-5            [-1, 192, 6, 6]         166,080
              ReLU-6            [-1, 192, 6, 6]               0
            Conv2d-7             [-1, 24, 3, 3]          41,496
              ReLU-8             [-1, 24, 3, 3]               0
           Flatten-9                  [-1, 216]               0
        Unflatten-10             [-1, 24, 3, 3]               0
  ConvTranspose2d-11            [-1, 192, 6, 6]          41,664
  ConvTranspose2d-12             [-1, 96, 8, 8]         165,984
             ReLU-13             [-1, 96, 8, 8]               0
  ConvTranspose2d-14           [-1, 48, 12, 12]          18,480
             ReLU-15           [-1, 48, 12, 12]               0
  ConvTranspose2d-16            [-1, 1, 24, 24]             433
================================================================
Total params: 453,145
Trainable params: 453,145
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.57
Params size (MB): 1.73
Estimated Total Size (MB): 2.30
----------------------------------------------------------------
Locals
{'__name__': '__main__', '__doc__': "\nThis script is only for image reconstruction\n\nNote the following:\nReconstructor (at least the first architecture) will be from Ibrar's presentation\n21 (input with minmaxscaler and tanh) (final layer tanh input )\n    21.1 (input with tanh final with tanh)\n\nAutoencoder (will be modified Autoencoder_config (where 0014.pt is))\n14.1 (first mod to 0014.pt LR to 108)\n\nAutoencoder complete linear\n", '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x154d3ed23190>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': '/home/kunet.ae/100053678/eit/autoencoders/eit.py', '__cached__': None, 'pd': <module 'pandas' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/pandas/__init__.py'>, 'plt': <module 'matplotlib.pyplot' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/matplotlib/pyplot.py'>, 'np': <module 'numpy' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/numpy/__init__.py'>, 'torch': <module 'torch' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/__init__.py'>, 'nn': <module 'torch.nn' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/nn/__init__.py'>, 'yaml': <module 'yaml' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/yaml/__init__.py'>, 'summary': <function summary at 0x154c72b03600>, 'DataLoader': <class 'torch.utils.data.dataloader.DataLoader'>, 'Dataset': <class 'torch.utils.data.dataset.Dataset'>, 'transforms': <module 'torchvision.transforms' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/transforms/__init__.py'>, 'time': <module 'time' (built-in)>, 'datetime': <class 'datetime.datetime'>, 'sys': <module 'sys' (built-in)>, 'Union': typing.Union, 'Optional': typing.Optional, 'ksp': <function ksp at 0x154c6e833880>, 'kspo': <function kspo at 0x154c6e833920>, 'optimizer_build': <function optimizer_build at 0x154c6e8339c0>, 'DiffImg': <class 'utils.classes.DiffImg'>, 'AutoencoderEIT_config': <class 'utils.classes.AutoencoderEIT_config'>, 'AutoencoderEIT': <class 'utils.classes.AutoencoderEIT'>, 'AutoencoderEIT142': <class 'utils.classes.AutoencoderEIT142'>, 'Reconstructor': <class 'utils.classes.Reconstructor'>, 'Autoencoder_Linear': <class 'utils.classes.Autoencoder_Linear'>, 'V2ImgLR': <class 'utils.classes.V2ImgLR'>, 'VoltageReconsturctor': <class 'utils.classes.VoltageReconsturctor'>, 'Diff2Image': <class 'utils.classes.Diff2Image'>, 'AutoencoderEIT_v': <class 'utils.classes.AutoencoderEIT_v'>, 'MinMax': <class 'utils.classes.MinMax'>, 'VoltageAE': <class 'utils.classes.VoltageAE'>, 'ResidualBlock': <class 'utils.classes.ResidualBlock'>, 'VoltageAE_base': <class 'utils.classes.VoltageAE_base'>, 'vAE': <class 'utils.classes.vAE'>, 'F': <module 'torch.nn.functional' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/nn/functional.py'>, 'ssim': <function structural_similarity at 0x154c6b696b60>, 'deepcopy': <function deepcopy at 0x154d2c03c680>, 'start': 1701294024.5777657, 'seed': 64, 'batch_size': 8, 'epochs': 200, 'device': device(type='cuda'), 'lrs': [-1], 'i': 0, 'lr': -1, 'ID': '14.2.1.retraining.1', 'nownow': datetime.datetime(2023, 11, 30, 1, 40, 24, 605132), 'TASK': 'img', 'CONDUCTANCE_VALUES': '', 'id_config': '14.2.1.retraining.1.20231130014024', 'DIFFS_IMGS_TRAIN_PATH': './data/eit/diffs_imgs_train.csv', 'DIFFS_IMGS_TEST_PATH': './data/eit/diffs_imgs_test.csv', 'LOSS_TRACKER_PATH': './results/loss_tracker_img.csv', 'MODEL_STATEDICT_SAVE_PATH': './models/img/14.2.1.retraining.1.20231130014024_img.pth', 'MODEL_SAVE_PATH': './models/img/14.2.1.retraining.1.20231130014024_img.pt', 'diff_transform': Compose(
    ToTensor()
), 'img_transform': Compose(
    ToTensor()
), 'train_dataset': <utils.classes.DiffImg object at 0x154d2a481550>, 'train_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x154c69547a90>, 'test_dataset': <utils.classes.DiffImg object at 0x154c6e862ad0>, 'test_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x154c6e21d090>, 'recon': AutoencoderEIT(
  (encoder): Sequential(
    (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))
    (3): ReLU()
    (4): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1))
    (5): ReLU()
    (6): Conv2d(192, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): ReLU()
    (8): Flatten(start_dim=1, end_dim=-1)
  )
  (decoder): Sequential(
    (0): Unflatten(dim=1, unflattened_size=(24, 3, 3))
    (1): ConvTranspose2d(24, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (2): ConvTranspose2d(192, 96, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
    (4): ConvTranspose2d(96, 48, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))
    (5): ReLU()
    (6): ConvTranspose2d(48, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  )
), 'param': Parameter containing:
tensor([0.0010], device='cuda:0', requires_grad=True)}
Training started!! - Reconstruction
Epoch:0, Epoch Loss: 0.003966, Loss:0.001012, MSE Loss: 0.000621, SSIM: 0.014025
Best state dict, with mse_loss 0.00, yet found @ 0...
slurmstepd: error: *** JOB 2610739 ON gpu-10-3 CANCELLED AT 2023-11-30T01:40:53 ***
