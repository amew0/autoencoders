14.2.1.retraining.2
14.2.1.retrainig.1 retraining
Importing finished!!
cuda is going to be used!!
Dataset loaded!! Length (train dataset) - 24000
Only gonna be shown once!
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 48, 12, 12]             480
              ReLU-2           [-1, 48, 12, 12]               0
            Conv2d-3             [-1, 96, 8, 8]          18,528
              ReLU-4             [-1, 96, 8, 8]               0
            Conv2d-5            [-1, 192, 6, 6]         166,080
              ReLU-6            [-1, 192, 6, 6]               0
            Conv2d-7             [-1, 24, 3, 3]          41,496
              ReLU-8             [-1, 24, 3, 3]               0
           Flatten-9                  [-1, 216]               0
        Unflatten-10             [-1, 24, 3, 3]               0
  ConvTranspose2d-11            [-1, 192, 6, 6]          41,664
  ConvTranspose2d-12             [-1, 96, 8, 8]         165,984
             ReLU-13             [-1, 96, 8, 8]               0
  ConvTranspose2d-14           [-1, 48, 12, 12]          18,480
             ReLU-15           [-1, 48, 12, 12]               0
  ConvTranspose2d-16            [-1, 1, 24, 24]             433
================================================================
Total params: 453,145
Trainable params: 453,145
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.57
Params size (MB): 1.73
Estimated Total Size (MB): 2.30
----------------------------------------------------------------
Locals
{'__name__': '__main__', '__doc__': "\nThis script is only for image reconstruction\n\nNote the following:\nReconstructor (at least the first architecture) will be from Ibrar's presentation\n21 (input with minmaxscaler and tanh) (final layer tanh input )\n    21.1 (input with tanh final with tanh)\n\nAutoencoder (will be modified Autoencoder_config (where 0014.pt is))\n14.1 (first mod to 0014.pt LR to 108)\n\nAutoencoder complete linear\n", '__package__': None, '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x152bf2a0b190>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__file__': '/home/kunet.ae/100053678/eit/autoencoders/eit.py', '__cached__': None, 'pd': <module 'pandas' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/pandas/__init__.py'>, 'plt': <module 'matplotlib.pyplot' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/matplotlib/pyplot.py'>, 'np': <module 'numpy' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/numpy/__init__.py'>, 'torch': <module 'torch' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/__init__.py'>, 'nn': <module 'torch.nn' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/nn/__init__.py'>, 'yaml': <module 'yaml' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/yaml/__init__.py'>, 'summary': <function summary at 0x152b2696b600>, 'DataLoader': <class 'torch.utils.data.dataloader.DataLoader'>, 'Dataset': <class 'torch.utils.data.dataset.Dataset'>, 'transforms': <module 'torchvision.transforms' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torchvision/transforms/__init__.py'>, 'time': <module 'time' (built-in)>, 'datetime': <class 'datetime.datetime'>, 'sys': <module 'sys' (built-in)>, 'Union': typing.Union, 'Optional': typing.Optional, 'ksp': <function ksp at 0x152b224af880>, 'kspo': <function kspo at 0x152b224af920>, 'optimizer_build': <function optimizer_build at 0x152b224af9c0>, 'DiffImg': <class 'utils.classes.DiffImg'>, 'AutoencoderEIT_config': <class 'utils.classes.AutoencoderEIT_config'>, 'AutoencoderEIT': <class 'utils.classes.AutoencoderEIT'>, 'AutoencoderEIT142': <class 'utils.classes.AutoencoderEIT142'>, 'Reconstructor': <class 'utils.classes.Reconstructor'>, 'Autoencoder_Linear': <class 'utils.classes.Autoencoder_Linear'>, 'V2ImgLR': <class 'utils.classes.V2ImgLR'>, 'VoltageReconsturctor': <class 'utils.classes.VoltageReconsturctor'>, 'Diff2Image': <class 'utils.classes.Diff2Image'>, 'AutoencoderEIT_v': <class 'utils.classes.AutoencoderEIT_v'>, 'MinMax': <class 'utils.classes.MinMax'>, 'VoltageAE': <class 'utils.classes.VoltageAE'>, 'ResidualBlock': <class 'utils.classes.ResidualBlock'>, 'VoltageAE_base': <class 'utils.classes.VoltageAE_base'>, 'vAE': <class 'utils.classes.vAE'>, 'F': <module 'torch.nn.functional' from '/home/kunet.ae/100053678/.conda/envs/eit/lib/python3.11/site-packages/torch/nn/functional.py'>, 'ssim': <function structural_similarity at 0x152b1f722b60>, 'deepcopy': <function deepcopy at 0x152bdfd24680>, 'start': 1701294191.6790185, 'seed': 64, 'batch_size': 8, 'epochs': 200, 'device': device(type='cuda'), 'lrs': [-1], 'i': 0, 'lr': -1, 'ID': '14.2.1.retraining.2', 'nownow': datetime.datetime(2023, 11, 30, 1, 43, 11, 706149), 'TASK': 'img', 'CONDUCTANCE_VALUES': '', 'id_config': '14.2.1.retraining.2.20231130014311', 'DIFFS_IMGS_TRAIN_PATH': './data/eit/diffs_imgs_train.csv', 'DIFFS_IMGS_TEST_PATH': './data/eit/diffs_imgs_test.csv', 'LOSS_TRACKER_PATH': './results/loss_tracker_img.csv', 'MODEL_STATEDICT_SAVE_PATH': './models/img/14.2.1.retraining.2.20231130014311_img.pth', 'MODEL_SAVE_PATH': './models/img/14.2.1.retraining.2.20231130014311_img.pt', 'diff_transform': Compose(
    ToTensor()
), 'img_transform': Compose(
    ToTensor()
), 'train_dataset': <utils.classes.DiffImg object at 0x152b1d436cd0>, 'train_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x152b26f92dd0>, 'test_dataset': <utils.classes.DiffImg object at 0x152b1d103b90>, 'test_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x152b1d103bd0>, 'recon': AutoencoderEIT(
  (encoder): Sequential(
    (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))
    (3): ReLU()
    (4): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1))
    (5): ReLU()
    (6): Conv2d(192, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): ReLU()
    (8): Flatten(start_dim=1, end_dim=-1)
  )
  (decoder): Sequential(
    (0): Unflatten(dim=1, unflattened_size=(24, 3, 3))
    (1): ConvTranspose2d(24, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (2): ConvTranspose2d(192, 96, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
    (4): ConvTranspose2d(96, 48, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))
    (5): ReLU()
    (6): ConvTranspose2d(48, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  )
), 'param': Parameter containing:
tensor([0.0010], device='cuda:0', requires_grad=True)}
Training started!! - Reconstruction
Epoch:0, Epoch Loss: 0.003966, Loss:0.001012, MSE Loss: 0.000621, SSIM: 0.014025
Best state dict, with mse_loss 0.000621, yet found @ 0...
Best state dict, with mse_loss 0.000542, yet found @ 7...
Epoch:10, Epoch Loss: 0.003941, Loss:0.000788, MSE Loss: 0.000681, SSIM: 0.008960
Epoch:20, Epoch Loss: 0.004130, Loss:0.001275, MSE Loss: 0.000778, SSIM: 0.017718
Epoch:30, Epoch Loss: 0.004036, Loss:0.002061, MSE Loss: 0.000605, SSIM: 0.035175
Best state dict, with mse_loss 0.000538, yet found @ 34...
Epoch:40, Epoch Loss: 0.003916, Loss:0.004653, MSE Loss: 0.000874, SSIM: 0.084309
Epoch:50, Epoch Loss: 0.004060, Loss:0.001194, MSE Loss: 0.000554, SSIM: 0.018331
Best state dict, with mse_loss 0.000497, yet found @ 59...
Epoch:60, Epoch Loss: 0.004163, Loss:0.003956, MSE Loss: 0.000637, SSIM: 0.072753
Epoch:70, Epoch Loss: 0.004142, Loss:0.000790, MSE Loss: 0.000566, SSIM: 0.010126
Epoch:80, Epoch Loss: 0.003933, Loss:0.002197, MSE Loss: 0.000603, SSIM: 0.037907
Epoch:90, Epoch Loss: 0.004140, Loss:0.001156, MSE Loss: 0.000606, SSIM: 0.017059
Best state dict, with mse_loss 0.000471, yet found @ 95...
Epoch:100, Epoch Loss: 0.004141, Loss:0.001600, MSE Loss: 0.000661, SSIM: 0.025404
Best state dict, with mse_loss 0.000418, yet found @ 101...
Epoch:110, Epoch Loss: 0.003916, Loss:0.001047, MSE Loss: 0.000535, SSIM: 0.015597
Epoch:120, Epoch Loss: 0.004012, Loss:0.001165, MSE Loss: 0.000416, SSIM: 0.019143
Best state dict, with mse_loss 0.000416, yet found @ 120...
Epoch:130, Epoch Loss: 0.003956, Loss:0.001650, MSE Loss: 0.000605, SSIM: 0.026943
Epoch:140, Epoch Loss: 0.004061, Loss:0.000992, MSE Loss: 0.000489, SSIM: 0.014944
Epoch:150, Epoch Loss: 0.003766, Loss:0.000844, MSE Loss: 0.000567, SSIM: 0.011224
Epoch:160, Epoch Loss: 0.004160, Loss:0.002331, MSE Loss: 0.000567, SSIM: 0.040943
Epoch:170, Epoch Loss: 0.004392, Loss:0.001345, MSE Loss: 0.000842, SSIM: 0.018474
Epoch:180, Epoch Loss: 0.004013, Loss:0.001421, MSE Loss: 0.000703, SSIM: 0.021401
Epoch:190, Epoch Loss: 0.004219, Loss:0.005390, MSE Loss: 0.000641, SSIM: 0.101384
Epoch:199, Epoch Loss: 0.004174, Loss:0.003397, MSE Loss: 0.000612, SSIM: 0.061814
Avg Test Loss: MSE: 0.06420152939949185, SSIM: 0.718476300462478
Max Test Loss: MSE: 0.30375608801841736 SSIM: 0.9743640619738999
Min Test Loss: MSE: 0.0005090355989523232 SSIM: 0.1736011444332285
written to: ./results/loss_tracker_img.csv
written to: ./models/img/14.2.1.retraining.2.20231130014311_img.pth
written to: ./models/img/14.2.1.retraining.2.20231130014311_img.pt
Elapsed time: 2457.2389471530914 seconds.
