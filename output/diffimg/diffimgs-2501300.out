34.1
decoder_14.2_first_conv2d_removed
Importing finished!!
cuda is going to be used!!
Dataset loaded!!
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 48, 12, 12]           1,248
              ReLU-2           [-1, 48, 12, 12]               0
            Conv2d-3             [-1, 96, 8, 8]          18,528
              ReLU-4             [-1, 96, 8, 8]               0
            Conv2d-5            [-1, 192, 6, 6]         166,080
              ReLU-6            [-1, 192, 6, 6]               0
            Conv2d-7             [-1, 24, 3, 3]          41,496
              ReLU-8             [-1, 24, 3, 3]               0
           Flatten-9                  [-1, 216]               0
        Unflatten-10             [-1, 24, 3, 3]               0
  ConvTranspose2d-11            [-1, 192, 6, 6]          41,664
  ConvTranspose2d-12             [-1, 96, 8, 8]         165,984
             ReLU-13             [-1, 96, 8, 8]               0
  ConvTranspose2d-14           [-1, 48, 12, 12]          18,480
             ReLU-15           [-1, 48, 12, 12]               0
  ConvTranspose2d-16            [-1, 1, 24, 24]             433
             Tanh-17            [-1, 1, 24, 24]               0
================================================================
Total params: 453,913
Trainable params: 227,352
Non-trainable params: 226,561
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.57
Params size (MB): 1.73
Estimated Total Size (MB): 2.30
----------------------------------------------------------------
None
Training started!!
Epoch:0, Loss:0.015961
Epoch:1, Loss:0.015910
Epoch:2, Loss:0.015617
Epoch:3, Loss:0.015562
Epoch:4, Loss:0.015831
Epoch:5, Loss:0.015800
Epoch:6, Loss:0.015667
Epoch:7, Loss:0.015237
Epoch:8, Loss:0.014429
Epoch:9, Loss:0.014503
Epoch:10, Loss:0.014088
Epoch:11, Loss:0.014182
Epoch:12, Loss:0.014672
Epoch:13, Loss:0.014737
Epoch:14, Loss:0.014394
Epoch:15, Loss:0.013991
Epoch:16, Loss:0.013335
Epoch:17, Loss:0.013463
Epoch:18, Loss:0.012998
Epoch:19, Loss:0.012911
Epoch:20, Loss:0.012511
Epoch:21, Loss:0.012286
Epoch:22, Loss:0.012463
Epoch:23, Loss:0.012544
Epoch:24, Loss:0.011913
Epoch:25, Loss:0.012479
Epoch:26, Loss:0.011865
Epoch:27, Loss:0.011740
Epoch:28, Loss:0.012129
Epoch:29, Loss:0.011863
Epoch:30, Loss:0.011730
Epoch:31, Loss:0.011412
Epoch:32, Loss:0.011805
Epoch:33, Loss:0.012000
Epoch:34, Loss:0.011070
Epoch:35, Loss:0.011197
Epoch:36, Loss:0.011187
Epoch:37, Loss:0.011424
Epoch:38, Loss:0.011038
Epoch:39, Loss:0.011510
Epoch:40, Loss:0.011434
Epoch:41, Loss:0.011489
Epoch:42, Loss:0.011701
Epoch:43, Loss:0.011512
Epoch:44, Loss:0.010501
Epoch:45, Loss:0.010469
Epoch:46, Loss:0.010354
Epoch:47, Loss:0.010520
Epoch:48, Loss:0.009482
Epoch:49, Loss:0.009658
Epoch:50, Loss:0.009633
Epoch:51, Loss:0.009469
Epoch:52, Loss:0.009222
Epoch:53, Loss:0.009217
Epoch:54, Loss:0.008794
Epoch:55, Loss:0.009188
Epoch:56, Loss:0.008541
Epoch:57, Loss:0.008711
Epoch:58, Loss:0.008277
Epoch:59, Loss:0.007956
Epoch:60, Loss:0.008497
Epoch:61, Loss:0.008078
Epoch:62, Loss:0.008336
Epoch:63, Loss:0.007325
Epoch:64, Loss:0.008920
Epoch:65, Loss:0.007141
Epoch:66, Loss:0.008363
Epoch:67, Loss:0.007824
Epoch:68, Loss:0.008892
Epoch:69, Loss:0.008569
Epoch:70, Loss:0.008244
Epoch:71, Loss:0.008239
Epoch:72, Loss:0.009452
Epoch:73, Loss:0.010017
Epoch:74, Loss:0.009012
Epoch:75, Loss:0.008769
Epoch:76, Loss:0.009186
Epoch:77, Loss:0.008310
Epoch:78, Loss:0.008886
Epoch:79, Loss:0.008550
Epoch:80, Loss:0.008351
Epoch:81, Loss:0.007744
Epoch:82, Loss:0.008376
Epoch:83, Loss:0.008743
Epoch:84, Loss:0.008716
Epoch:85, Loss:0.009041
Epoch:86, Loss:0.008611
Epoch:87, Loss:0.009090
Epoch:88, Loss:0.008488
Epoch:89, Loss:0.007800
Epoch:90, Loss:0.008671
Epoch:91, Loss:0.007550
Epoch:92, Loss:0.007672
Epoch:93, Loss:0.008024
Epoch:94, Loss:0.007140
Epoch:95, Loss:0.007985
Epoch:96, Loss:0.008140
Epoch:97, Loss:0.008639
Epoch:98, Loss:0.008275
Epoch:99, Loss:0.007384
Epoch:100, Loss:0.009370
Epoch:101, Loss:0.008791
Epoch:102, Loss:0.007921
Epoch:103, Loss:0.009480
Epoch:104, Loss:0.008428
Epoch:105, Loss:0.008545
Epoch:106, Loss:0.008255
Epoch:107, Loss:0.008117
Epoch:108, Loss:0.008347
Epoch:109, Loss:0.008451
Epoch:110, Loss:0.007916
Epoch:111, Loss:0.008618
Epoch:112, Loss:0.007930
Epoch:113, Loss:0.007696
Epoch:114, Loss:0.007360
Epoch:115, Loss:0.007749
Epoch:116, Loss:0.007752
Epoch:117, Loss:0.009121
Epoch:118, Loss:0.007393
Epoch:119, Loss:0.007981
Epoch:120, Loss:0.007127
Epoch:121, Loss:0.007638
Epoch:122, Loss:0.009007
Epoch:123, Loss:0.007679
Epoch:124, Loss:0.007301
Epoch:125, Loss:0.008945
Epoch:126, Loss:0.007649
Epoch:127, Loss:0.008769
Epoch:128, Loss:0.008729
Epoch:129, Loss:0.007646
Epoch:130, Loss:0.008340
Epoch:131, Loss:0.010349
Epoch:132, Loss:0.007486
Epoch:133, Loss:0.009082
Epoch:134, Loss:0.008909
Epoch:135, Loss:0.008328
Epoch:136, Loss:0.009730
Epoch:137, Loss:0.009005
Epoch:138, Loss:0.009480
Epoch:139, Loss:0.007979
Epoch:140, Loss:0.009280
Epoch:141, Loss:0.008989
Epoch:142, Loss:0.008468
Epoch:143, Loss:0.008842
Epoch:144, Loss:0.008756
Epoch:145, Loss:0.008398
Epoch:146, Loss:0.009269
Epoch:147, Loss:0.008974
Epoch:148, Loss:0.010318
Epoch:149, Loss:0.008911
Epoch:150, Loss:0.008866
Epoch:151, Loss:0.009087
Epoch:152, Loss:0.009984
Epoch:153, Loss:0.008023
Epoch:154, Loss:0.009253
Epoch:155, Loss:0.009881
Epoch:156, Loss:0.009299
Epoch:157, Loss:0.011306
Epoch:158, Loss:0.009224
Epoch:159, Loss:0.010685
Epoch:160, Loss:0.010346
Epoch:161, Loss:0.011437
Epoch:162, Loss:0.009918
Epoch:163, Loss:0.011611
Epoch:164, Loss:0.011004
Epoch:165, Loss:0.009866
Epoch:166, Loss:0.009285
Epoch:167, Loss:0.010017
Epoch:168, Loss:0.009627
Epoch:169, Loss:0.010866
Epoch:170, Loss:0.010306
Epoch:171, Loss:0.010363
Epoch:172, Loss:0.010260
Epoch:173, Loss:0.010144
Epoch:174, Loss:0.009296
Epoch:175, Loss:0.011049
Epoch:176, Loss:0.010064
Epoch:177, Loss:0.009707
Epoch:178, Loss:0.010219
Epoch:179, Loss:0.010651
Epoch:180, Loss:0.011344
Epoch:181, Loss:0.010914
Epoch:182, Loss:0.009170
Epoch:183, Loss:0.010354
Epoch:184, Loss:0.009848
Epoch:185, Loss:0.009950
Epoch:186, Loss:0.009434
Epoch:187, Loss:0.010402
Epoch:188, Loss:0.010100
Epoch:189, Loss:0.011058
Epoch:190, Loss:0.010108
Epoch:191, Loss:0.010067
Epoch:192, Loss:0.010104
Epoch:193, Loss:0.009075
Epoch:194, Loss:0.010012
Epoch:195, Loss:0.010359
Epoch:196, Loss:0.011942
Epoch:197, Loss:0.011166
Epoch:198, Loss:0.009789
Epoch:199, Loss:0.010049
Avg Test Loss: 0.01684172185463831
written to: ./results/loss_tracker_diffimg.csv
written to: ./models/34.1.20231110010409_diffimg.pth
written to: ./models/34.1.20231110010409_diffimg.pt
Elapsed time: 1552.653935432434 seconds.
